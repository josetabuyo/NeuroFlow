# ğŸ§  Connectionist Neural Automaton (CNA)

**Un AutÃ³mata Celular Neuronal para la BÃºsqueda de Inteligencia Artificial**

> *"Del caracol Aplysia al pez cebra: Un modelo conexionista escalable que unifica memoria, predicciÃ³n y acciÃ³n"*

---

## ğŸ“– Ãndice

1. [VisiÃ³n FilosÃ³fica](#visiÃ³n-filosÃ³fica)
2. [Fundamentos CientÃ­ficos](#fundamentos-cientÃ­ficos)
3. [Â¿Por quÃ© un AutÃ³mata Celular Neuronal?](#por-quÃ©-un-autÃ³mata-celular-neuronal)
4. [Del Teatro Cartesiano a la Consciencia Distribuida](#del-teatro-cartesiano-a-la-consciencia-distribuida)
5. [Arquitectura: Reglas Emergentes vs. Hardcoded](#arquitectura-reglas-emergentes-vs-hardcoded)
6. [Stack TecnolÃ³gico](#stack-tecnolÃ³gico)
7. [Plan de Desarrollo](#plan-de-desarrollo)
8. [Notebook 1: AutÃ³mata Celular Base](#notebook-1-autÃ³mata-celular-base)
9. [Notebook 2: Mapas Auto-Organizados (Kohonen)](#notebook-2-mapas-auto-organizados-kohonen)
10. [Notebook 3: Memoria Temporal y PredicciÃ³n (HTM)](#notebook-3-memoria-temporal-y-predicciÃ³n-htm)
11. [Notebook 4: UI Interactiva y RobÃ³tica](#notebook-4-ui-interactiva-y-robÃ³tica)
12. [Compartir en la Web](#compartir-en-la-web)
13. [ApÃ©ndices](#apÃ©ndices)
14. [README.md del Proyecto](#readmemd-del-proyecto)

---

## ğŸ¯ VisiÃ³n FilosÃ³fica

### El Problema de la IA Actual: La Gran Brecha

Hoy existe una **brecha fundamental** en la inteligencia artificial:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              LA GRAN BRECHA DE LA IA ACTUAL               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                           â”‚
â”‚  [IA DE LENGUAJE]        âŒ        [ROBÃ“TICA MÃ“VIL]     â”‚
â”‚   GPT, Transformers      GAP       NavegaciÃ³n fÃ­sica     â”‚
â”‚   PredicciÃ³n palabras             SelecciÃ³n acciones     â”‚
â”‚   Sin embodiment                   Sin memoria espacial  â”‚
â”‚   Sin mundo fÃ­sico                 Sin pensamiento       â”‚
â”‚                                                           â”‚
â”‚                    Â¿QuÃ© falta?                           â”‚
â”‚                                                           â”‚
â”‚     ğŸ§  CEREBRO DE BAJO NIVEL                             â”‚
â”‚        â€¢ Memoria espacial distribuida                     â”‚
â”‚        â€¢ PredicciÃ³n de acciones (no palabras)            â”‚
â”‚        â€¢ IntegraciÃ³n sensorial continua                   â”‚
â”‚        â€¢ Self-organization espontÃ¡nea                     â”‚
â”‚        â€¢ Embodiment (cuerpo â†” cerebro)                   â”‚
â”‚                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### La SoluciÃ³n: Connectionist Neural Automaton

Este proyecto propone un **autÃ³mata celular neuronal** que:

#### 1ï¸âƒ£ **No tiene "Teatro Cartesiano"** (Daniel Dennett)

Daniel Dennett criticÃ³ la idea del "teatro cartesiano": la falacia de que existe un lugar central en el cerebro donde un "homÃºnculo" (pequeÃ±o observador) ve la experiencia consciente en una pantalla mental.

**Problema:** Si la consciencia ocurre en un lugar especÃ­fico, Â¿quiÃ©n observa ese lugar? â†’ RegresiÃ³n infinita

**SoluciÃ³n del CNA:** 
- **No hay centro de control**
- La "inteligencia" emerge de interacciones distribuidas
- Cada neurona es autÃ³noma, solo conoce sus vecinos
- El comportamiento global surge de reglas locales

```python
# âŒ ANTI-PATRÃ“N (Teatro Cartesiano)
class Brain:
    def think(self):
        data = self.collect_all_sensory_data()
        decision = self.central_controller.decide(data)  # â† HomÃºnculo!
        self.execute(decision)

# âœ… PATRÃ“N CNA (Consciencia Distribuida)
class NeuralAutomaton:
    def step(self):
        for neuron in self.neurons:
            # Cada neurona solo ve sus vecinos locales
            neuron.update(neuron.neighbors)  # â† Regla local
        # El pensamiento EMERGE de las interacciones
```

#### 2ï¸âƒ£ **Reglas Emergentes** (no hardcoded)

Inspirado en autÃ³matas celulares (Conway, Von Neumann), pero con diferencia crucial:

| Tipo | Reglas | Aprendizaje | Ejemplo |
|------|--------|-------------|---------|
| **ClÃ¡sico** | Hardcoded | âŒ No | Game of Life: "si 3 vecinos vivos â†’ nacer" |
| **CNA** | En sinapsis | âœ… SÃ­ | Peso sinÃ¡ptico aprende: w += Î· Â· pre Â· post |

```python
# AutÃ³mata clÃ¡sico: Reglas fijas
def conway_rule(cell, neighbors):
    alive_neighbors = sum(neighbors)
    if cell == 1:  # Viva
        return 1 if alive_neighbors in [2, 3] else 0
    else:  # Muerta
        return 1 if alive_neighbors == 3 else 0

# CNA: Reglas aprendidas en pesos sinÃ¡pticos
class Synapse:
    def __init__(self):
        self.weight = random()  # â† Regla inicial aleatoria
    
    def update(self, pre_value, post_value):
        # Hebbian: Regla emerge del uso
        self.weight += 0.01 * pre_value * post_value
```

**Ventaja:** El CNA puede **aprender** quÃ© reglas funcionan para una tarea especÃ­fica.

#### 3ï¸âƒ£ **Memoria Distribuida** (moving patterns)

La memoria no estÃ¡ "almacenada" en un lugar, sino que son **patrones de activaciÃ³n que se mueven** por la matriz neuronal:

```
t=0:  [0 0 1 1 0 0 0 0]  â† PatrÃ³n inicial (ej: "vi comida")
      â†“ activaciÃ³n se propaga
t=1:  [0 1 1 1 1 0 0 0]
      â†“
t=2:  [1 1 0 0 1 1 0 0]  â† El patrÃ³n "viaja"
      â†“
t=3:  [0 0 0 1 1 1 1 0]  â† Activa neuronas motoras â†’ "moverme"
```

- **Memoria de corto plazo:** ActivaciÃ³n sostenida en regiones internas
- **Memoria de largo plazo:** Pesos sinÃ¡pticos modificados (Hebbian)
- **Memory replay:** Patrones se pueden "reproducir" (como en ratas durmiendo)

#### 4ï¸âƒ£ **Self-Organizing Maps** (Teuvo Kohonen)

El modelo de Kohonen (SOM) muestra cÃ³mo redes neuronales forman **mapas topolÃ³gicos** espontÃ¡neamente:

**FunciÃ³n "Sombrero Mexicano" (Mexican Hat):**

```
     ActivaciÃ³n
        â†‘
        â”‚      â•±â€¾â€¾â•²         â† ExcitaciÃ³n central
        â”‚     â•±    â•²
    â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€  â† LÃ­nea base
        â”‚   â•±        â•²     â† InhibiciÃ³n lateral
        â”‚  â•±          â•²
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Distancia
```

- **Centro:** Neurona ganadora + vecinos cercanos se activan (excitaciÃ³n)
- **Periferia:** Vecinos lejanos se inhiben (competencia)
- **Resultado:** Clustering espontÃ¡neo de patrones similares

**En el cerebro real:**
- **Corteza auditiva:** Mapas tonotÃ³picos (frecuencias vecinas â†’ neuronas vecinas)
- **Corteza visual:** Mapas retinotÃ³picos (campo visual â†’ topologÃ­a cortical)
- **Corteza somatosensorial:** HomÃºnculo de Penfield

**En el CNA:**

```python
class Dendrite:
    def lateral_inhibition(self, neighbors, radius=3):
        # Sombrero mexicano
        for i, neighbor in enumerate(neighbors):
            distance = abs(i - self.position)
            if distance <= radius:
                # ExcitaciÃ³n: Kohonen neighborhood
                self.value += 0.1 * neighbor.value * (1 - distance/radius)
            else:
                # InhibiciÃ³n lateral
                self.value -= 0.05 * neighbor.value
```

#### 5ï¸âƒ£ **Hierarchical Temporal Memory** (Jeff Hawkins)

En *On Intelligence* (2004), Jeff Hawkins propone que el neocÃ³rtex funciona como un **sistema de predicciÃ³n temporal jerÃ¡rquica**:

**Principios del HTM:**

1. **Sparse Distributed Representations:** Solo ~2% de neuronas activas simultÃ¡neamente
2. **Sequence Learning:** Aprende patrones temporales (Aâ†’Bâ†’C)
3. **Prediction:** Predice el siguiente estado basado en secuencias aprendidas
4. **Hierarchy:** Niveles superiores aprenden patrones de patrones

```
Nivel 3: [Concepto abstracto: "peligro"]
           â†‘
Nivel 2: [Secuencia: "sombraâ†’movimientoâ†’forma"]
           â†‘
Nivel 1: [PÃ­xeles: bordes, texturas]
           â†‘
Entrada: [Sensor visual]
```

**En el CNA:**

```python
class HTMLayer:
    def predict(self, current_state):
        # Busca secuencias conocidas: Aâ†’Bâ†’?
        predicted_next = self.sequence_memory.get(current_state)
        
        # Pre-activa neuronas esperadas (predictive state)
        for neuron in predicted_next:
            neuron.tension += 0.5  # Umbral mÃ¡s bajo
        
        # Si la predicciÃ³n acierta â†’ refuerzo
        # Si falla â†’ sorpresa â†’ aprendizaje
```

#### 6ï¸âƒ£ **Place Cells & Grid Cells** (O'Keefe, Moser)

Descubrimientos en ratas (Premio Nobel 2014):

- **Place cells** (hipocampo): Neuronas que se activan en lugares especÃ­ficos
- **Grid cells** (corteza entorrinal): PatrÃ³n hexagonal que cubre el espacio

**Hallazgos recientes (2024):**
- Las ratas pueden **imaginar lugares** sin estar allÃ­ (memory replay)
- Los patrones de activaciÃ³n "repasan" rutas durante el sueÃ±o
- **Predictive grid cells:** Se activan en la posiciÃ³n FUTURA (no solo actual)

```
    Lugar A              Lugar B
      [â—]â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[â—]
       â†‘                  â†‘
    Place cell 1      Place cell 2

Durante navegaciÃ³n:
  t=0: Place cell 1 activa âœ“
  t=1: Ambas activas (transiciÃ³n)
  t=2: Place cell 2 activa âœ“

Durante imaginaciÃ³n (sin movimiento):
  t=0: Place cell 1 activa
  t=1: Secuencia se reproduce internamente
  t=2: Place cell 2 activa â† Â¡Sin moverse!
```

**En el CNA:**

```python
class SpatialMap:
    def __init__(self):
        self.place_cells = {}  # (x,y) â†’ neuron
        self.grid_cells = []   # PatrÃ³n hexagonal
    
    def imagine_path(self, start, goal):
        # Memory replay: Activa secuencia sin input sensorial
        path = self.find_path(start, goal)
        for position in path:
            self.place_cells[position].activate()
            yield position  # â† PredicciÃ³n
```

#### 7ï¸âƒ£ **IntegraciÃ³n Sensorial** (multimodal)

El cerebro integra informaciÃ³n de mÃºltiples fuentes:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         INTEGRACIÃ“N SENSORIAL            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                          â”‚
â”‚  [Vista]    [Tacto]    [OÃ­do]          â”‚
â”‚     â†“          â†“         â†“              â”‚
â”‚  RegiÃ³n     RegiÃ³n    RegiÃ³n            â”‚
â”‚  ENTRADA    ENTRADA   ENTRADA           â”‚
â”‚     â•²         â”‚        â•±                â”‚
â”‚      â•²        â”‚       â•±                 â”‚
â”‚       â•²       â”‚      â•±                  â”‚
â”‚        â†“      â†“     â†“                   â”‚
â”‚     RegiÃ³n INTERNA                      â”‚
â”‚   (Neuronas integradoras)               â”‚
â”‚            â†“                             â”‚
â”‚       RegiÃ³n SALIDA                      â”‚
â”‚      (Neuronas motoras)                  â”‚
â”‚            â†“                             â”‚
â”‚        [AcciÃ³n]                          â”‚
â”‚                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Ejemplo del pez cebra (2024):**
- Imaging de cerebro completo durante comportamiento libre
- Neuronas en el preoptic nucleus integran:
  - InformaciÃ³n visual (novedad del tanque)
  - Estado interno (curiosidad vs. miedo)
  - Memoria (lugares ya explorados)
- La activaciÃ³n integrada predice: explorar vs. esconderse

#### 8ï¸âƒ£ **AcciÃ³n como PredicciÃ³n** (no palabras)

La IA actual predice **tokens** (palabras). Este modelo predice **acciones**:

| Modelo | Entrada | PredicciÃ³n | Objetivo |
|--------|---------|------------|----------|
| **GPT** | "El gato estÃ¡ en el..." | "sofÃ¡" | Completar frase |
| **CNA** | [Vista: comida a izquierda] | mover_izquierda() | Supervivencia |

**"Pensar es predecir quÃ© hacer"** (embodied cognition)

```python
class EmbodiedBrain:
    def think(self, sensory_input):
        # 1. Integrar sensores
        state = self.integrate(sensory_input)
        
        # 2. Predecir consecuencias de acciones
        predictions = {
            'move_left': self.predict(state, action='left'),
            'move_right': self.predict(state, action='right'),
            'stay': self.predict(state, action='stay')
        }
        
        # 3. Seleccionar acciÃ³n con mejor predicciÃ³n
        best_action = max(predictions, key=lambda a: predictions[a].value)
        
        return best_action
```

#### 9ï¸âƒ£ **Escalabilidad: De Aplysia a Pez Cebra**

**Aplysia californica (caracol marino):**
- 20,000 neuronas (vs. 86 mil millones en humanos)
- Eric Kandel (Nobel 2000) descubriÃ³ mecanismos de **memoria y aprendizaje**
- Reflejo de retracciÃ³n branquial: sensibilizaciÃ³n y habituaciÃ³n
- **LecciÃ³n:** Mecanismos bÃ¡sicos (Hebbian, LTP) son universales

**ProgresiÃ³n:**

```
Aplysia       C. elegans      Mosca       Pez cebra      Rata         Humano
(20K)         (302)           (100K)      (100M)         (200M)       (86B)
   â†“             â†“              â†“            â†“             â†“            â†“
Reflejos â†’ Quimiotaxis â†’ NavegaciÃ³n â†’ Mapas â†’ PlanificaciÃ³n â†’ Lenguaje
```

**Estrategia del CNA:**

1. **Fase 1:** Implementar modelo de Aplysia (reflejos condicionados)
2. **Fase 2:** AÃ±adir navegaciÃ³n espacial (pez cebra, place cells)
3. **Fase 3:** Integrar HTM para memoria temporal (rata)
4. **Fase 4:** Conectar con transformers para procesamiento simbÃ³lico

#### ğŸ”Ÿ **ConexiÃ³n con Transformers** (lo mejor de ambos mundos)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ARQUITECTURA HÃBRIDA CNA+TRANSFORMERS           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  [NIVEL ALTO: Transformers]                                â”‚
â”‚   â€¢ Embeddings de lenguaje                                 â”‚
â”‚   â€¢ Razonamiento simbÃ³lico                                 â”‚
â”‚   â€¢ AtenciÃ³n global                                        â”‚
â”‚   â€¢ "QuÃ© hacer en esta situaciÃ³n"                         â”‚
â”‚            â†•                                               â”‚
â”‚  [INTERFAZ: Embedding <-> ActivaciÃ³n]                      â”‚
â”‚   â€¢ Traducir palabras â†’ patrones neuronales               â”‚
â”‚   â€¢ Traducir activaciones â†’ acciones simbÃ³licas           â”‚
â”‚            â†•                                               â”‚
â”‚  [NIVEL BAJO: CNA]                                         â”‚
â”‚   â€¢ AutÃ³mata celular neuronal                             â”‚
â”‚   â€¢ Memoria espacial distribuida                           â”‚
â”‚   â€¢ PredicciÃ³n de acciones fÃ­sicas                         â”‚
â”‚   â€¢ "CÃ³mo ejecutar la acciÃ³n"                             â”‚
â”‚            â†•                                               â”‚
â”‚  [CUERPO: Sensores + Actuadores]                           â”‚
â”‚   â€¢ Vista, tacto, propriocepciÃ³n                          â”‚
â”‚   â€¢ Motores, mÃºsculos                                      â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Ejemplo de integraciÃ³n:**

```python
# Transformer de alto nivel decide QUÃ‰ hacer
instruction = gpt_model("Estoy viendo comida a la izquierda")
# Output: "move_to_food"

# CNA traduce a activaciÃ³n neuronal
embedding = embed(instruction)  # [0.2, 0.8, -0.3, ...]
motor_region.set_pattern(embedding)

# CNA ejecuta CÃ“MO hacerlo
for t in range(100):
    cna.step()  # AutÃ³mata neuronal genera secuencia motora
    robot.apply_forces(cna.motor_output)
```

---

## ğŸ”¬ Fundamentos CientÃ­ficos

### Estudios que validan este enfoque

#### 1. **Zebrafish Whole-Brain Imaging (2024-2025)**

**Paper:** "Whole-brain mapping in adult zebrafish and identification of a novel tank test functional connectome"

**Hallazgos:**
- Imaging del cerebro completo durante comportamiento libre
- TÃ©cnica: Light-sheet microscopy + machine learning
- El **preoptic nucleus anterior** actÃºa como hub integrando:
  - TelencÃ©falo ventral (emociÃ³n)
  - Regiones sensoriales (vista)
  - NÃºcleos de neurotransmisores (dopamina, serotonina)

**Relevancia para CNA:**
- Valida el modelo de **regiones integradoras**
- Las neuronas internas no tienen funciÃ³n predefinida, sino que emergen como hubs
- La activaciÃ³n se propaga espacialmente (como en autÃ³mata celular)

#### 2. **Predictive Grid Cells (2024)**

**Paper:** "Mapping future locations" (Nature Neuroscience)

**Hallazgos:**
- Grid cells en corteza entorrinal **predicen posiciÃ³n futura**
- No solo codifican "dÃ³nde estoy", sino "dÃ³nde estarÃ©"
- Durante imaginaciÃ³n, las secuencias se activan sin movimiento

**Relevancia para CNA:**
- La predicciÃ³n es fundamental (HTM correcto)
- Memory replay = activaciÃ³n interna sin input
- El cerebro es una "mÃ¡quina de predecir acciones"

#### 3. **Neural Cellular Automata (2020)**

**Paper:** "Growing Neural Cellular Automata" (Distill.pub, Google Research)

**Hallazgos:**
- Reemplazar reglas fijas de autÃ³matas con **redes neuronales entrenables**
- Cada cÃ©lula ejecuta la misma regla (red neuronal)
- Emergen propiedades: morfogÃ©nesis, regeneraciÃ³n, auto-reparaciÃ³n

**Relevancia para CNA:**
- Demuestra que **autÃ³matas + aprendizaje = comportamiento emergente complejo**
- Confirma que reglas locales + gradiente â†’ inteligencia global

#### 4. **Hierarchical Temporal Memory - Numenta**

**Paper:** "A Framework for Intelligence and Cortical Function Based on Grid Cells in the Neocortex" (Hawkins et al.)

**Hallazgos:**
- El neocÃ³rtex usa **columnas corticales** como unidades repetitivas
- Cada columna aprende secuencias temporales
- Niveles superiores aprenden patrones de patrones

**Relevancia para CNA:**
- Arquitectura jerÃ¡rquica es clave para escalabilidad
- PredicciÃ³n temporal debe ser explÃ­cita en el modelo

#### 5. **Kohonen Self-Organizing Maps (1990)**

**Paper:** "The self-organizing map" (Teuvo Kohonen, Proceedings of the IEEE)

**Hallazgos:**
- Mapas topolÃ³gicos emergen de aprendizaje competitivo
- FunciÃ³n de vecindad (sombrero mexicano) crucial
- Similares a mapas corticales reales (visual, auditivo, somatosensorial)

**Relevancia para CNA:**
- **Dendritas laterales de excitaciÃ³n/inhibiciÃ³n** implementan esto
- Clustering espontÃ¡neo sin supervisiÃ³n

---

## â“ Â¿Por quÃ© un AutÃ³mata Celular Neuronal?

### ComparaciÃ³n de paradigmas

| Aspecto | Red Neuronal ClÃ¡sica | Transformer | **AutÃ³mata Celular Neuronal** |
|---------|---------------------|-------------|-------------------------------|
| **Conectividad** | Feed-forward fija | All-to-all attention | Vecindad local dinÃ¡mica |
| **Temporalidad** | ImplÃ­cita (RNN) | Posicional encoding | ExplÃ­cita (estado evoluciona) |
| **Memoria** | Pesos estÃ¡ticos | Context window | Patrones dinÃ¡micos distribuidos |
| **Espacialidad** | No explÃ­cita | No explÃ­cita | âœ… TopologÃ­a 2D/3D nativa |
| **Aprendizaje** | Backprop global | Backprop global | Hebbian local + Backprop |
| **Escalabilidad** | O(NÂ²) conexiones | O(NÂ²) atenciÃ³n | O(N) vecindad constante |
| **Interpretabilidad** | Baja | Muy baja | âœ… Alta (ver patrones evolucionar) |
| **Embodiment** | No | No | âœ… SÃ­ (topologÃ­a = espacio fÃ­sico) |

### Ventajas del CNA

#### 1. **Localidad espacial explÃ­cita**

```python
# Red feed-forward: Neurona 5 puede conectar con cualquiera
layer[5].forward([w1*n0, w2*n1, w3*n2, ..., w100*n99])  # â† No locality

# CNA: Neurona (x,y) solo ve vecinos 3x3
grid[x][y].forward([
    grid[x-1][y-1], grid[x][y-1], grid[x+1][y-1],  # Arriba
    grid[x-1][y],   grid[x][y],   grid[x+1][y],    # Centro
    grid[x-1][y+1], grid[x][y+1], grid[x+1][y+1]   # Abajo
])  # â† Solo 9 vecinos, no 100
```

**Beneficio:** 
- Menos parÃ¡metros (O(N) vs O(NÂ²))
- MÃ¡s eficiente en GPU (convoluciones)
- Mapas espaciales emergen naturalmente

#### 2. **EvoluciÃ³n temporal visible**

```python
# Transformer: Un forward pass opaco
output = transformer(input)  # Â¿QuÃ© pasÃ³ aquÃ­? ğŸ¤·

# CNA: Puedes ver cada paso
for t in range(100):
    cna.step()
    visualize(cna.grid)  # â† Ver patrones moverse, emerger, colapsar
```

**Beneficio:**
- Debugging intuitivo
- ExperimentaciÃ³n interactiva
- Educativo (ver "pensamiento" en tiempo real)

#### 3. **Memoria distribuida persistente**

```python
# RNN: Memoria en hidden state (se desvanece)
h_t = tanh(W_hh @ h_{t-1} + W_xh @ x_t)  # â† Gradientes exploding/vanishing

# Transformer: Memoria en context window (limitado)
output = attention(query, keys[:max_length])  # â† Solo Ãºltimos N tokens

# CNA: Memoria en activaciÃ³n + pesos (persistente)
grid[x][y].value = 0.8  # â† Permanece hasta que algo la cambie
synapse.weight += hebbian_update()  # â† Memoria a largo plazo
```

**Beneficio:**
- No hay "olvido catastrÃ³fico"
- Memoria de corto plazo (activaciÃ³n) + largo plazo (pesos)
- Memory replay factible

#### 4. **Reglas emergentes, no diseÃ±adas**

```python
# Algoritmo A*: Reglas de bÃºsqueda hardcoded
def a_star(start, goal):
    open_set = {start}
    while open_set:
        current = min(open_set, key=lambda n: f_score[n])  # â† Regla fija
        # ...

# CNA: Reglas emergen del aprendizaje
# Entrenas con muchos ejemplos (start, goal) â†’ path
# La red aprende a propagar activaciÃ³n en la direcciÃ³n correcta
```

**Beneficio:**
- GeneralizaciÃ³n a nuevos escenarios
- No necesitas programar todas las reglas
- Adapta las reglas si el entorno cambia

#### 5. **Unifica percepciÃ³n y acciÃ³n**

```
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         ARQUITECTURA CLÃSICA            â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  [PercepciÃ³n] â†’ [Razonamiento] â†’ [AcciÃ³n] â”‚
    â”‚      CNN          MLP            Policy   â”‚
    â”‚   (separado)   (separado)      (separado) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         ARQUITECTURA CNA                â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚             [ÃšNICA MATRIZ]              â”‚
    â”‚  RegiÃ³n ENTRADA â†’ RegiÃ³n INTERNA â†’ RegiÃ³n SALIDA â”‚
    â”‚  (pÃ­xeles)        (procesamiento)   (motores)     â”‚
    â”‚  Todo es el mismo autÃ³mata evolutivo    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Beneficio:**
- Feedback sensorimotor directo
- Aprendizaje end-to-end natural
- Embodiment intrÃ­nseco

---

## ğŸ­ Del Teatro Cartesiano a la Consciencia Distribuida

### El Teatro Cartesiano (lo que NO queremos)

RenÃ© Descartes imaginÃ³ la glÃ¡ndula pineal como el punto donde mente (res cogitans) y cuerpo (res extensa) interactuaban.

Daniel Dennett critica esta idea y su versiÃ³n moderna materialista:

```
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚      TEATRO CARTESIANO             â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚                                    â”‚
    â”‚  [Ojos] â”€â”€â”€â”€â”€â†’ [Imagen en retina] â”‚
    â”‚                      â†“             â”‚
    â”‚  [OÃ­dos] â”€â”€â”€â”€â†’ [Corteza visual]   â”‚
    â”‚                      â†“             â”‚
    â”‚  [Tacto] â”€â”€â”€â”€â†’ [Procesamiento]    â”‚
    â”‚                      â†“             â”‚
    â”‚              â”â”â”â”â”â”â”â”â”â”â”â”â”“        â”‚
    â”‚              â”ƒ  PANTALLA  â”ƒ        â”‚
    â”‚              â”ƒ    MENTAL  â”ƒ        â”‚
    â”‚              â”—â”â”â”â”â”â”â”â”â”â”â”â”›        â”‚
    â”‚                    â†‘               â”‚
    â”‚              [HOMÃšNCULO]           â”‚
    â”‚           (Â¿quiÃ©n mira?)           â”‚
    â”‚                  â†“                 â”‚
    â”‚              [DECISIÃ“N]            â”‚
    â”‚                                    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         
         âŒ Problema: RegresiÃ³n infinita
         Â¿QuiÃ©n observa al homÃºnculo?
```

### Consciencia Distribuida (lo que SÃ queremos)

**Modelo "Multiple Drafts" de Dennett:**

- No hay un lugar donde "todo se junta"
- MÃºltiples procesos paralelos compiten y colaboran
- La experiencia consciente es un producto emergente
- No hay un "momento de presentaciÃ³n" Ãºnico

```
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         CONSCIENCIA DISTRIBUIDA                â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚                                                â”‚
    â”‚  [Ojos] â”€â”€â†’ [V1] â”€â”€â†’ [V2] â”€â”€â†’ [V4] â”€â”€â†’ [IT]  â”‚
    â”‚               â†“       â†“       â†“       â†“       â”‚
    â”‚  [OÃ­dos] â”€â”€â†’ [A1] â”€â”€â†’ [A2] â”€â”€â†’ [IntegraciÃ³n] â”‚
    â”‚               â†“       â†“           â†“    â†“      â”‚
    â”‚  [Tacto] â”€â”€â†’ [S1] â”€â”€â†’ [Parietal] â†“    â†“      â”‚
    â”‚               â†“           â†“       â†“    â†“      â”‚
    â”‚             [Memoria] â†â†’ [PredicciÃ³n]  â†“      â”‚
    â”‚                 â†“           â†“         â†“       â”‚
    â”‚               [Motor] â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†“       â”‚
    â”‚                                                â”‚
    â”‚   âœ… No hay centro                            â”‚
    â”‚   âœ… Todo interactÃºa con todo                 â”‚
    â”‚   âœ… La "consciencia" EMERGE                  â”‚
    â”‚                                                â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ImplementaciÃ³n en el CNA

```python
class ConnessionistNeuralAutomaton:
    def __init__(self):
        # No hay "control central"
        self.neurons = self.create_grid(128, 128)
        
        # Cada neurona es autÃ³noma
        for neuron in self.neurons:
            neuron.autonomous = True  # â† No espera Ã³rdenes
    
    def step(self):
        # âŒ NO HACER (centralizado):
        # self.central_controller.decide()
        # for neuron in self.neurons:
        #     neuron.value = self.central_controller.outputs[neuron.id]
        
        # âœ… SÃ HACER (distribuido):
        for neuron in self.neurons:
            # Cada neurona decide basada SOLO en sus vecinos
            neuron.update_from_neighbors()
        
        # El comportamiento global EMERGE
        # No hay "quien decide" globalmente
```

**ComparaciÃ³n con el proyecto original:**

> *"No hay operaciones que se hagan por fuera de las conexiones, el modelo es conexionista puro, no hay un espectador dentro del cerebro regulando la actividad, puede distribuirse sin problemas."*

âœ… **Esto es exactamente Dennett**: Sin teatro, sin espectador, sin homÃºnculo.

---

## âš™ï¸ Arquitectura: Reglas Emergentes vs. Hardcoded

### AutÃ³matas Celulares ClÃ¡sicos

#### Game of Life (John Conway)

Reglas fijas:

```python
def game_of_life(cell, neighbors):
    alive_neighbors = sum(neighbors)
    
    if cell == 1:  # CÃ©lula viva
        if alive_neighbors < 2:
            return 0  # Muerte por soledad
        elif alive_neighbors in [2, 3]:
            return 1  # Supervivencia
        else:
            return 0  # Muerte por sobrepoblaciÃ³n
    else:  # CÃ©lula muerta
        if alive_neighbors == 3:
            return 1  # Nacimiento
        else:
            return 0  # Sigue muerta
```

**Comportamiento emergente:**
- Gliders (planeadores que se mueven)
- Oscillators (osciladores periÃ³dicos)
- Still lifes (patrones estÃ¡ticos)

**LimitaciÃ³n:** Las reglas son fijas. No puede "aprender" quÃ© reglas funcionan mejor.

#### AutÃ³mata de Von Neumann

MÃ¡s complejo: 29 estados por cÃ©lula, reglas para auto-replicaciÃ³n.

**Logro:** DemostrÃ³ que autÃ³matas pueden replicarse (concepto de vida artificial).

**LimitaciÃ³n:** Reglas diseÃ±adas manualmente, no aprendidas.

### Neural Cellular Automata (Mordvintsev et al., 2020)

**InnovaciÃ³n:** Reemplazar reglas fijas con **redes neuronales diferenciables**:

```python
class NeuralCA(nn.Module):
    def __init__(self, channels=16):
        super().__init__()
        # La "regla" es una red neuronal
        self.network = nn.Sequential(
            nn.Conv2d(channels*3, 128, 1),  # 3x3 vecindad
            nn.ReLU(),
            nn.Conv2d(128, channels, 1)
        )
    
    def forward(self, grid):
        # Percibir vecindad (3x3 convolution)
        perception = self.perceive(grid)
        
        # Aplicar regla aprendida
        update = self.network(perception)
        
        # Actualizar con residual connection
        return grid + update * 0.1
    
    def perceive(self, grid):
        # 3x3 Sobel filters para detectar gradientes
        return torch.cat([
            F.conv2d(grid, self.sobel_x),
            F.conv2d(grid, self.sobel_y),
            grid
        ], dim=1)
```

**Entrenamiento:**

```python
# Objetivo: Crecer un emoji ğŸ¦ desde una semilla
target_image = load_emoji("ğŸ¦")
seed = torch.zeros_like(target_image)
seed[0, height//2, width//2] = 1.0  # Semilla central

# Entrenar
optimizer = torch.optim.Adam(nca.parameters())
for epoch in range(1000):
    # Simular evoluciÃ³n
    state = seed.clone()
    for t in range(64):  # 64 pasos de autÃ³mata
        state = nca(state)
    
    # Loss: Â¿Se parece al emoji objetivo?
    loss = F.mse_loss(state, target_image)
    
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
```

**Resultado:** La red aprende reglas que hacen crecer el emoji. Bonus: regenera si se daÃ±a.

### Connectionist Neural Automaton (nuestro modelo)

**Diferencia con NCA clÃ¡sico:**

| Aspecto | NCA (Mordvintsev) | **CNA (nuestro)** |
|---------|-------------------|-------------------|
| Objetivo | MorfogÃ©nesis (crecer imagen) | **CogniciÃ³n** (pensar, actuar) |
| Regla | Una red neuronal global | **Sinapsis individuales** (mÃ¡s granular) |
| Aprendizaje | Backprop supervisado | **Hebbian + Backprop hÃ­brido** |
| Estructura | Grid homogÃ©neo | **Regiones** (ENTRADA/INTERNA/SALIDA) |
| BiologÃ­a | Inspirado en desarrollo | **Inspirado en cerebro funcional** |

**Arquitectura del CNA:**

```python
class CNA:
    def __init__(self, width=64, height=64):
        # Matriz neuronal 2D
        self.grid = [[Neuron(x, y) for x in range(width)] for y in range(height)]
        
        # Regiones funcionales (como en el cerebro)
        self.regions = {
            'ENTRADA': self.grid[0:16],      # Sensores (arriba)
            'INTERNA': self.grid[16:48],     # Procesamiento (centro)
            'SALIDA':  self.grid[48:64],     # Motores (abajo)
            'DOLOR':   self.grid[60:64]      # SeÃ±al de error
        }
        
        # Conectar neuronas
        for neuron in self.all_neurons():
            neuron.dendrites = [
                Dendrite([
                    Synapse(neighbor, weight=random())
                    for neighbor in self.get_neighbors(neuron, radius=3)
                ])
                for _ in range(4)  # 4 dendritas por neurona
            ]
    
    def step(self):
        # 1. Procesar dendritas (AND difuso)
        for neuron in self.all_neurons():
            for dendrite in neuron.dendrites:
                dendrite.procesar()  # Promedio de sinapsis
        
        # 2. Procesar neuronas (OR difuso + activaciÃ³n)
        for neuron in self.all_neurons():
            neuron.procesar()  # Max de dendritas
            neuron.activar()   # Umbral
        
        # 3. Entrenar sinapsis (Hebbian)
        if self.learning_enabled:
            for neuron in self.all_neurons():
                for dendrite in neuron.dendrites:
                    dendrite.entrenar()  # w += Î·Â·preÂ·post

class Synapse:
    def __init__(self, source_neuron, weight=0.5):
        self.source = source_neuron
        self.weight = weight  # â† AQUÃ ESTÃ LA REGLA
    
    def procesar(self):
        # Similaridad entre neuronas
        pre = self.source.valor
        post = self.target.valor
        return self.weight * (1 - abs(pre - post))
    
    def entrenar(self):
        # Hebbian: "Neurons that fire together, wire together"
        pre = self.source.valor
        post = self.target.valor
        
        self.weight += 0.01 * pre * post  # â† REGLA APRENDIDA
        
        # Poda sinÃ¡ptica
        if self.weight < 0.1:
            self.weight = 0  # Eliminar sinapsis dÃ©bil
```

**Ventaja:** Cada sinapsis tiene su propia "regla" (peso), y todas aprenden en paralelo.

### ComparaciÃ³n: Reglas Hardcoded vs. Emergentes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 REGLAS HARDCODED                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                           â”‚
â”‚  if (neighbors == 3) { alive = true; }                  â”‚
â”‚  else if (neighbors < 2) { alive = false; }             â”‚
â”‚                                                           â”‚
â”‚  âœ… Pros:                                               â”‚
â”‚     â€¢ Simple de entender                                 â”‚
â”‚     â€¢ Determinista                                       â”‚
â”‚                                                           â”‚
â”‚  âŒ Contras:                                            â”‚
â”‚     â€¢ No se adapta a nuevas situaciones                 â”‚
â”‚     â€¢ DiseÃ±ador debe saber las reglas correctas         â”‚
â”‚     â€¢ No generaliza                                      â”‚
â”‚                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 REGLAS EMERGENTES (CNA)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                           â”‚
â”‚  weight += learning_rate * pre_activation * post_activation â”‚
â”‚  output = sum(weight[i] * neighbor[i])                  â”‚
â”‚                                                           â”‚
â”‚  âœ… Pros:                                               â”‚
â”‚     â€¢ Aprende reglas Ã³ptimas para la tarea              â”‚
â”‚     â€¢ Se adapta si el entorno cambia                    â”‚
â”‚     â€¢ Descubre soluciones no obvias                     â”‚
â”‚     â€¢ Generaliza a situaciones nuevas                   â”‚
â”‚                                                           â”‚
â”‚  âŒ Contras:                                            â”‚
â”‚     â€¢ Necesita datos de entrenamiento                   â”‚
â”‚     â€¢ Menos predecible                                   â”‚
â”‚     â€¢ Puede converger a Ã³ptimos locales                 â”‚
â”‚                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Ejemplo concreto:**

**Tarea:** Navegar un robot hacia comida.

```python
# âŒ Reglas hardcoded
def navigate(sensors):
    if sensors['left'] > sensors['right']:
        return 'turn_left'
    elif sensors['right'] > sensors['left']:
        return 'turn_right'
    else:
        return 'forward'

# âœ… Reglas emergentes (CNA)
# Entrenar con 1000 ejemplos de (sensores, acciÃ³n correcta)
for episode in range(1000):
    state = env.reset()
    for t in range(100):
        # Poner sensores en regiÃ³n ENTRADA
        cna.set_input_region(state)
        
        # Propagar activaciÃ³n
        for _ in range(10):
            cna.step()
        
        # Leer acciÃ³n de regiÃ³n SALIDA
        action = cna.get_output_region()
        
        # Ejecutar
        next_state, reward = env.step(action)
        
        # Entrenar (Hebbian + refuerzo)
        if reward > 0:
            cna.reinforce_active_synapses()  # â† Reforzar pesos actuales
        else:
            cna.weaken_active_synapses()
```

DespuÃ©s de entrenamiento, el CNA ha aprendido reglas como:

- "Si neurona de sensor izquierdo activa â†’ neurona motora izquierda activa"
- "Si ambos sensores activos â†’ neurona motora frontal activa"
- Y muchas reglas sutiles difÃ­ciles de programar manualmente

---

## ğŸ› ï¸ Stack TecnolÃ³gico

### Lenguaje y Entorno

- **Python 3.11+**: Lenguaje principal
- **Jupyter Notebook**: Entorno interactivo
- **Google Colab**: Hosting gratuito con GPU (T4, P100)
- **Binder/MyBinder**: Alternativa open-source

### ComputaciÃ³n Neuronal

| LibrerÃ­a | PropÃ³sito | Â¿Por quÃ©? |
|----------|-----------|-----------|
| **PyTorch** | Framework de deep learning | â€¢ DinÃ¡mico (vs. TensorFlow estÃ¡tico)<br>â€¢ Excelente para investigaciÃ³n<br>â€¢ `torch.compile()` para optimizaciÃ³n<br>â€¢ Soporte nativo de GPU |
| **NumPy** | Operaciones matriciales | â€¢ Base de todo<br>â€¢ IntegraciÃ³n perfecta con PyTorch |

### Transformers (Nivel Alto)

| LibrerÃ­a | PropÃ³sito | Â¿Por quÃ©? |
|----------|-----------|-----------|
| **Transformers (Hugging Face)** | Modelos pre-entrenados | â€¢ Embeddings de lenguaje<br>â€¢ BERT, GPT, etc.<br>â€¢ FÃ¡cil integraciÃ³n |
| **Sentence-Transformers** | Embeddings semÃ¡nticos | â€¢ Texto â†’ Vector denso<br>â€¢ ComparaciÃ³n de significado |

### VisualizaciÃ³n

| LibrerÃ­a | PropÃ³sito | Â¿Por quÃ©? |
|----------|-----------|-----------|
| **ipycanvas** | Canvas interactivo | â€¢ Dibujar pÃ­xeles en tiempo real<br>â€¢ Eventos de mouse<br>â€¢ Renderizado eficiente |
| **ipywidgets** | Controles UI | â€¢ Sliders, botones, dropdowns<br>â€¢ Interactividad sin JavaScript |
| **Matplotlib** | GrÃ¡ficos 2D | â€¢ Plots cientÃ­ficos<br>â€¢ Heatmaps, evoluciÃ³n temporal |
| **Plotly** | GrÃ¡ficos interactivos | â€¢ 3D opcional<br>â€¢ Zoom, hover |

### OptimizaciÃ³n

```python
# torch.compile() - PyTorch 2.0+
@torch.compile(mode="reduce-overhead")
def cna_step(states, weights):
    # 100x mÃ¡s rÃ¡pido que cÃ³digo Python puro
    return F.conv2d(states, weights)

# Mixed Precision
from torch.cuda.amp import autocast, GradScaler
scaler = GradScaler()
with autocast():
    output = model(input)  # FP16/BF16 automÃ¡tico

# Flash Attention (para transformers grandes)
from torch.nn.functional import scaled_dot_product_attention
attn = scaled_dot_product_attention(q, k, v)  # 2-4x mÃ¡s rÃ¡pido
```

### Estructura de Archivos

```
CNA_Project/
â”œâ”€â”€ README.md                    # â† DescripciÃ³n del proyecto
â”œâ”€â”€ requirements.txt             # â† pip install -r requirements.txt
â”œâ”€â”€ environment.yml              # â† conda env create -f environment.yml
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_Automata_Base.ipynb
â”‚   â”œâ”€â”€ 02_SOM_Kohonen.ipynb
â”‚   â”œâ”€â”€ 03_HTM_Prediccion.ipynb
â”‚   â””â”€â”€ 04_UI_Robotica.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ cna/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ core.py              # Neurona, Dendrita, Sinapsis
â”‚   â”‚   â”œâ”€â”€ automaton.py         # CNA main class
â”‚   â”‚   â”œâ”€â”€ regions.py           # RegiÃ³n ENTRADA/SALIDA/INTERNA
â”‚   â”‚   â”œâ”€â”€ learning.py          # Hebbian, STDP
â”‚   â”‚   â””â”€â”€ visualization.py     # Rendering
â”‚   â”œâ”€â”€ som/
â”‚   â”‚   â”œâ”€â”€ kohonen.py           # Self-Organizing Map
â”‚   â”‚   â””â”€â”€ mexican_hat.py       # Lateral inhibition
â”‚   â”œâ”€â”€ htm/
â”‚   â”‚   â”œâ”€â”€ temporal_memory.py   # Hawkins HTM
â”‚   â”‚   â””â”€â”€ spatial_pooler.py
â”‚   â””â”€â”€ transformers/
â”‚       â”œâ”€â”€ embeddings.py        # Interfaz con HuggingFace
â”‚       â””â”€â”€ hybrid.py            # CNA + Transformer
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ aplysia_reflex.py        # Reflejo condicionado simple
â”‚   â”œâ”€â”€ zebrafish_navigation.py  # NavegaciÃ³n espacial
â”‚   â””â”€â”€ rat_memory_replay.py     # Memory replay
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ diagrams/                # Diagramas explicativos
â”‚   â””â”€â”€ videos/                  # Grabaciones de evoluciÃ³n
â””â”€â”€ tests/
    â”œâ”€â”€ test_neuron.py
    â”œâ”€â”€ test_automaton.py
    â””â”€â”€ test_learning.py
```

---

## ğŸ“… Plan de Desarrollo

### Fase 1: AutÃ³mata Celular Base (Notebook 1)

**Objetivo:** Implementar un autÃ³mata celular neuronal simple, mÃ¡s cercano a Conway pero con sinapsis aprendibles.

**Componentes:**

1. **Neurona bÃ¡sica:**
   - Estado: `valor` (0-1), `tension` (umbral)
   - MÃ©todo: `procesar()` (agregar dendritas), `activar()` (umbral)

2. **Dendrita:**
   - AgregaciÃ³n de sinapsis (AND difuso = promedio)
   - MÃ©todo: `procesar()`

3. **Sinapsis:**
   - Peso: `peso` (0-1)
   - MÃ©todo: `procesar()` (similaridad pesada), `entrenar()` (Hebbian)

4. **Red (CNA):**
   - Grid 2D (ej: 64x64)
   - Conectividad local (vecindad 3x3 o 5x5)
   - MÃ©todo: `step()` (un paso de tiempo)

5. **VisualizaciÃ³n:**
   - Heatmap de activaciÃ³n neuronal
   - AnimaciÃ³n de evoluciÃ³n temporal

**Experimentos:**

- Patrones oscilantes (como en Game of Life)
- PropagaciÃ³n de onda
- Reflejo simple (sensor â†’ motor)

**DuraciÃ³n:** 1-2 semanas

---

### Fase 2: Mapas Auto-Organizados (Notebook 2)

**Objetivo:** AÃ±adir Self-Organizing Maps (Kohonen) con inhibiciÃ³n lateral tipo sombrero mexicano.

**Componentes:**

1. **Mexican Hat Function:**
   ```python
   def mexican_hat(distance, sigma_excite=1.0, sigma_inhibit=3.0):
       excite = np.exp(-distance**2 / (2*sigma_excite**2))
       inhibit = 0.5 * np.exp(-distance**2 / (2*sigma_inhibit**2))
       return excite - inhibit
   ```

2. **Dendritas laterales:**
   - ExcitaciÃ³n: Dendritas conectadas a vecinos cercanos (peso positivo)
   - InhibiciÃ³n: Dendritas conectadas a vecinos lejanos (peso negativo)

3. **Aprendizaje competitivo:**
   - Winner-take-all (neurona con mayor activaciÃ³n)
   - Actualizar vecindad de ganador:
     ```python
     for neighbor in neighborhood(winner, radius=3):
         neighbor.synapses.weight += lr * (input - weight)
     ```

4. **Clustering:**
   - Entrenar con patrones de entrada (ej: dÃ­gitos MNIST)
   - Ver cÃ³mo emergen clusters topolÃ³gicos

**Experimentos:**

- Mapeo de colores RGB â†’ Grid 2D
- Clustering de embeddings de texto
- Mapas retinotÃ³picos (imagen â†’ activaciÃ³n espacial)

**DuraciÃ³n:** 1-2 semanas

---

### Fase 3: Memoria Temporal y PredicciÃ³n (Notebook 3)

**Objetivo:** Implementar Hierarchical Temporal Memory (Hawkins) para aprender secuencias y predecir.

**Componentes:**

1. **Sequence Memory:**
   ```python
   class SequenceMemory:
       def __init__(self):
           self.sequences = {}  # (state_t, state_{t-1}) â†’ count
       
       def learn(self, current, previous):
           key = (hash(current), hash(previous))
           self.sequences[key] = self.sequences.get(key, 0) + 1
       
       def predict(self, current):
           # Buscar quÃ© sigue despuÃ©s de 'current'
           candidates = [
               (next_state, count) 
               for (next_state, prev_state), count in self.sequences.items()
               if prev_state == hash(current)
           ]
           return max(candidates, key=lambda x: x[1])[0] if candidates else None
   ```

2. **Predictive State:**
   - Neuronas en "estado predictivo" (tensiÃ³n reducida)
   - Si la predicciÃ³n acierta â†’ refuerzo
   - Si falla â†’ sorpresa â†’ aprendizaje fuerte

3. **Columnas corticales:**
   - Grupos de neuronas que aprenden patrones
   - JerarquÃ­a: Nivel 1 â†’ Nivel 2 â†’ Nivel 3

4. **Sparse Distributed Representation:**
   - Solo 2% de neuronas activas simultÃ¡neamente
   - Aumenta capacidad de memoria

**Experimentos:**

- Aprender secuencias ABC, DEF â†’ predecir siguiente
- Navegar maze y predecir siguiente ubicaciÃ³n
- Memory replay: Reproducir secuencias sin input

**DuraciÃ³n:** 2-3 semanas

---

### Fase 4: UI Interactiva y RobÃ³tica (Notebook 4)

**Objetivo:** Crear interfaz para dibujar neuronas y controlar un robot simulado.

**Componentes:**

1. **Canvas interactivo (ipycanvas):**
   ```python
   from ipycanvas import Canvas
   canvas = Canvas(width=800, height=600)
   
   def on_mouse_down(x, y):
       grid_x, grid_y = canvas_to_grid(x, y)
       cna.grid[grid_x][grid_y].value = 1.0  # Activar neurona
       render()
   
   canvas.on_mouse_down(on_mouse_down)
   ```

2. **Controles (ipywidgets):**
   - Play/Pause/Step
   - Sliders: velocidad, learning rate, umbral
   - Dropdown: regiÃ³n (ENTRADA/SALIDA/INTERNA)
   - Brush size para dibujar

3. **Constructor de patrones:**
   - Cargar patrones predefinidos (como `conexionados.js`)
   - Guardar/cargar estados

4. **Robot simulado:**
   - Grid 32x32 con comida, obstÃ¡culos
   - Sensores: 8 direcciones (N, NE, E, SE, S, SW, W, NW)
   - Actuadores: Avanzar, girar
   - Objetivo: Aprender navegaciÃ³n con CNA

5. **MÃ©tricas:**
   - Plot de activaciÃ³n temporal
   - Histograma de pesos sinÃ¡pticos
   - Heatmap de place cells

**Experimentos:**

- Dibujar patrones manualmente y ver evoluciÃ³n
- Entrenar robot a encontrar comida
- Comparar CNA vs. Policy Gradient (RL)

**DuraciÃ³n:** 2-3 semanas

---

### Fase 5 (Opcional): IntegraciÃ³n con Transformers

**Objetivo:** Conectar CNA (bajo nivel) con Transformers (alto nivel).

**Arquitectura:**

```python
class HybridBrain:
    def __init__(self):
        self.cna = ConnessionistNeuralAutomaton(64, 64)
        self.transformer = AutoModel.from_pretrained("bert-base")
        self.embedding_bridge = nn.Linear(768, 64*64)  # BERT â†’ CNA
        self.action_bridge = nn.Linear(64*64, 512)     # CNA â†’ BERT
    
    def think(self, language_input, sensory_input):
        # 1. Procesar lenguaje (Transformer)
        lang_embedding = self.transformer(language_input).last_hidden_state.mean(1)
        
        # 2. Traducir a activaciÃ³n neuronal
        cna_pattern = self.embedding_bridge(lang_embedding).view(64, 64)
        self.cna.set_region('INTERNA', cna_pattern)
        
        # 3. Procesar sensores + lenguaje en CNA
        self.cna.set_region('ENTRADA', sensory_input)
        for _ in range(10):
            self.cna.step()
        
        # 4. Leer acciÃ³n y traducir a lenguaje
        action_pattern = self.cna.get_region('SALIDA').flatten()
        action_embedding = self.action_bridge(action_pattern)
        
        return action_embedding  # Puede conectar a decoder para generar texto
```

**Ejemplo de uso:**

```python
brain = HybridBrain()

# InstrucciÃ³n en lenguaje natural
instruction = tokenizer("Move to the red object", return_tensors="pt")

# Sensores del robot
sensors = torch.tensor([[0.2, 0.8, 0.0, 0.1, ...]])  # Valores normalizados

# Pensar
action_embedding = brain.think(instruction, sensors)

# Ejecutar
action = action_decoder(action_embedding)  # "move_forward", "turn_left", etc.
robot.execute(action)
```

**DuraciÃ³n:** 3-4 semanas

---

## ğŸ“˜ Notebook 1: AutÃ³mata Celular Base

### Objetivos

1. Implementar clases bÃ¡sicas: `Neurona`, `Dendrita`, `Sinapsis`
2. Crear `CNA` (Connectionist Neural Automaton)
3. Visualizar evoluciÃ³n temporal
4. Experimentos con patrones oscilantes y propagaciÃ³n

### InstalaciÃ³n

```python
# Celda 1: InstalaciÃ³n
!pip install torch torchvision numpy matplotlib ipycanvas ipywidgets
```

### ConfiguraciÃ³n

```python
# Celda 2: Imports y configuraciÃ³n
import torch
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation
from IPython.display import HTML, display
import ipywidgets as widgets
from ipycanvas import Canvas
import random
from dataclasses import dataclass
from typing import List, Tuple, Optional

# ConfiguraciÃ³n
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Usando: {device}")

# Reproducibilidad
torch.manual_seed(42)
np.random.seed(42)
random.seed(42)
```

### Clases Base

```python
# Celda 3: ConfiguraciÃ³n global
@dataclass
class Config:
    """ConfiguraciÃ³n global del sistema (como cfg/config.js)"""
    
    # Coeficientes de aprendizaje
    COEF_SINAPSIS_ENTRENAMIENTO: float = 0.1
    COEF_SINAPSIS_UMBRAL_PESO: float = 0.05
    COEF_SINAPSIS_PESO_MEDIO: float = 0.5
    
    # Umbrales de activaciÃ³n
    NEURONA_UMBRAL_ACTIVACION: float = 0.5
    NEURONA_TENSION_INICIAL: float = 1.0
    
    # Coeficientes de tensiÃ³n
    COEF_NEURONA_TENSION_RECUPERACION: float = 0.01
    COEF_NEURONA_TENSION_DISIPACION: float = 0.05
    
    # Regiones
    REGIONES: dict = None
    
    def __post_init__(self):
        if self.REGIONES is None:
            self.REGIONES = {
                'ENTRADA': 0,
                'SALIDA': 1,
                'INTERNA': 2,
                'DOLOR': 3
            }

config = Config()
```

```python
# Celda 4: Clase Sinapsis
class Sinapsis:
    """
    ConexiÃ³n entre dos neuronas con peso Hebbiano.
    Inspirado en: model/Sinapsis.js del proyecto original
    """
    
    def __init__(self, neurona_origen, peso: float = None):
        self.origen = neurona_origen  # Neurona presinÃ¡ptica
        self.destino = None           # Se asigna cuando se conecta a dendrita
        
        # Peso inicial aleatorio o especificado
        if peso is None:
            self.peso = random.uniform(0.3, 0.7)
        else:
            self.peso = peso
        
        # Para visualizaciÃ³n
        self.ultima_activacion = 0.0
    
    def procesar(self) -> float:
        """
        Calcula el valor que aporta esta sinapsis.
        Original: Usa similaridad entre origen y destino.
        """
        if self.origen is None:
            return 0.0
        
        valor_origen = self.origen.valor
        
        # Si hay destino, usar similaridad (como en original)
        if self.destino is not None:
            valor_destino = self.destino.valor
            similaridad = 1.0 - abs(valor_origen - valor_destino)
            self.ultima_activacion = self.peso * similaridad
        else:
            # Sin destino, simplemente pasar valor pesado
            self.ultima_activacion = self.peso * valor_origen
        
        return self.ultima_activacion
    
    def entrenar(self):
        """
        Aprendizaje Hebbiano: "Neurons that fire together, wire together"
        w += Î· * pre * post
        """
        if self.origen is None or self.destino is None:
            return
        
        pre = self.origen.valor
        post = self.destino.valor
        
        # Regla Hebbiana
        delta = config.COEF_SINAPSIS_ENTRENAMIENTO * pre * post
        self.peso += delta
        
        # Clamp peso entre [0, 1]
        self.peso = max(0.0, min(1.0, self.peso))
        
        # Poda sinÃ¡ptica (eliminar sinapsis dÃ©biles)
        if self.peso < config.COEF_SINAPSIS_UMBRAL_PESO:
            self.peso = 0.0
    
    def __repr__(self):
        return f"Sinapsis(peso={self.peso:.3f})"
```

```python
# Celda 5: Clase Dendrita
class Dendrita:
    """
    AgrupaciÃ³n de sinapsis que implementa lÃ³gica AND difusa.
    Inspirado en: model/Dendrita.js del proyecto original
    """
    
    def __init__(self, sinapsis: List[Sinapsis] = None):
        self.sinapsis = sinapsis if sinapsis is not None else []
        self.valor = 0.0
    
    def procesar(self) -> float:
        """
        Procesa todas las sinapsis y agrega sus valores.
        Original: Promedio de sinapsis activas (AND difuso)
        """
        if not self.sinapsis:
            self.valor = 0.0
            return self.valor
        
        # Filtrar sinapsis con peso > 0
        activas = [s for s in self.sinapsis if s.peso > 0]
        
        if not activas:
            self.valor = 0.0
            return self.valor
        
        # AND difuso: Promedio de valores de sinapsis
        suma = sum(s.procesar() for s in activas)
        self.valor = suma / len(activas)
        
        return self.valor
    
    def entrenar(self):
        """Entrena todas las sinapsis de esta dendrita"""
        for sinapsis in self.sinapsis:
            sinapsis.entrenar()
    
    def agregar_sinapsis(self, sinapsis: Sinapsis):
        """AÃ±ade una sinapsis a esta dendrita"""
        self.sinapsis.append(sinapsis)
        sinapsis.destino = self  # Asignar referencia inversa
    
    def __repr__(self):
        return f"Dendrita(valor={self.valor:.3f}, sinapsis={len(self.sinapsis)})"
```

```python
# Celda 6: Clase Neurona
class Neurona:
    """
    Unidad bÃ¡sica de procesamiento del CNA.
    Inspirado en: model/Neurona.js del proyecto original
    """
    
    def __init__(self, x: int, y: int, region: int = 2):
        # PosiciÃ³n en el grid
        self.x = x
        self.y = y
        
        # RegiÃ³n funcional
        self.region = region  # 0=ENTRADA, 1=SALIDA, 2=INTERNA, 3=DOLOR
        
        # Estado
        self.valor = 0.0      # ActivaciÃ³n actual
        self.activa = False    # Si estÃ¡ activada (valor > umbral)
        
        # TensiÃ³n superficial (umbral dinÃ¡mico)
        self.tension = config.NEURONA_TENSION_INICIAL
        
        # Dendritas (entradas)
        self.dendritas: List[Dendrita] = []
        
        # Historial (para visualizaciÃ³n)
        self.historial_valor = []
    
    def procesar(self):
        """
        Procesa todas las dendritas y calcula el nuevo valor.
        Original: OR difuso = mÃ¡ximo de dendritas
        """
        if not self.dendritas:
            return
        
        # Procesar cada dendrita
        valores_dendritas = [d.procesar() for d in self.dendritas]
        
        # OR difuso: MÃ¡ximo
        if valores_dendritas:
            self.valor = max(valores_dendritas)
        else:
            self.valor = 0.0
    
    def activar(self):
        """
        Compara valor con tensiÃ³n (umbral) y decide si activar.
        """
        if self.valor >= self.tension:
            self.activa = True
            self.valor = 1.0  # ActivaciÃ³n completa
            
            # Disipar tensiÃ³n (periodo refractario)
            self.tension = max(0.1, self.tension - config.COEF_NEURONA_TENSION_DISIPACION)
        else:
            self.activa = False
            
            # Recuperar tensiÃ³n gradualmente
            if self.tension < config.NEURONA_TENSION_INICIAL:
                self.tension += config.COEF_NEURONA_TENSION_RECUPERACION
    
    def entrenar(self):
        """Entrena todas las dendritas de esta neurona"""
        for dendrita in self.dendritas:
            dendrita.entrenar()
    
    def reset(self):
        """Resetea el estado de la neurona"""
        self.valor = 0.0
        self.activa = False
        self.tension = config.NEURONA_TENSION_INICIAL
    
    def __repr__(self):
        return f"Neurona({self.x},{self.y}, v={self.valor:.2f}, t={self.tension:.2f})"


class NeuronaEntrada(Neurona):
    """
    Neurona de entrada (sensorial).
    No procesa dendritas, su valor se setea externamente.
    """
    
    def __init__(self, x: int, y: int):
        super().__init__(x, y, region=0)  # RegiÃ³n ENTRADA
    
    def procesar(self):
        # No procesar dendritas, el valor viene del exterior
        pass
    
    def set_valor(self, valor: float):
        """Establece el valor directamente (desde sensores)"""
        self.valor = max(0.0, min(1.0, valor))
        self.activar()
```

### AutÃ³mata Celular

```python
# Celda 7: Clase CNA
class ConnessionistNeuralAutomaton:
    """
    AutÃ³mata Celular Neuronal principal.
    Grid 2D de neuronas con conectividad local.
    """
    
    def __init__(self, width: int = 64, height: int = 64, connect_radius: int = 3):
        self.width = width
        self.height = height
        self.connect_radius = connect_radius
        
        # Crear grid de neuronas
        self.grid = [[Neurona(x, y) for x in range(width)] for y in range(height)]
        
        # Aplanar para iteraciÃ³n fÃ¡cil
        self.neuronas = [n for row in self.grid for n in row]
        
        # Definir regiones
        self.definir_regiones()
        
        # Conectar neuronas
        self.conectar_localmente(radius=connect_radius)
        
        # EstadÃ­sticas
        self.paso_actual = 0
        self.learning_enabled = True
    
    def definir_regiones(self):
        """
        Define regiones funcionales en el grid.
        Similar a setupRegiones.js
        """
        h = self.height
        
        # ENTRADA: Arriba (primeras 16 filas)
        for y in range(min(16, h//4)):
            for x in range(self.width):
                self.grid[y][x].region = config.REGIONES['ENTRADA']
                self.grid[y][x] = NeuronaEntrada(x, y)
        
        # SALIDA: Abajo (Ãºltimas 16 filas)
        for y in range(max(0, h - 16), h):
            for x in range(self.width):
                self.grid[y][x].region = config.REGIONES['SALIDA']
        
        # DOLOR: Esquina inferior derecha
        for y in range(max(0, h - 8), h):
            for x in range(max(0, self.width - 8), self.width):
                self.grid[y][x].region = config.REGIONES['DOLOR']
        
        # INTERNA: Todo lo demÃ¡s (ya tiene regiÃ³n 2 por defecto)
    
    def get_neighbors(self, neuron: Neurona, radius: int = 3) -> List[Neurona]:
        """Obtiene vecinos dentro de un radio"""
        neighbors = []
        for dy in range(-radius, radius + 1):
            for dx in range(-radius, radius + 1):
                if dx == 0 and dy == 0:
                    continue
                
                nx, ny = neuron.x + dx, neuron.y + dy
                
                # Toroidal wrap (opcional)
                # nx = nx % self.width
                # ny = ny % self.height
                
                # Clamp (no wrap)
                if 0 <= nx < self.width and 0 <= ny < self.height:
                    neighbors.append(self.grid[ny][nx])
        
        return neighbors
    
    def conectar_localmente(self, radius: int = 3):
        """
        Conecta cada neurona con sus vecinos cercanos.
        Cada neurona tiene varias dendritas, cada dendrita tiene varias sinapsis.
        """
        num_dendritas = 4  # Como en el original
        
        for neuron in self.neuronas:
            # Saltar neuronas de entrada (no tienen dendritas)
            if isinstance(neuron, NeuronaEntrada):
                continue
            
            neighbors = self.get_neighbors(neuron, radius)
            
            if not neighbors:
                continue
            
            # Crear dendritas
            for _ in range(num_dendritas):
                dendrita = Dendrita()
                
                # Cada dendrita se conecta a subset de vecinos
                num_sinapsis = random.randint(2, min(8, len(neighbors)))
                vecinos_seleccionados = random.sample(neighbors, num_sinapsis)
                
                for vecino in vecinos_seleccionados:
                    sinapsis = Sinapsis(vecino)
                    sinapsis.destino = neuron
                    dendrita.agregar_sinapsis(sinapsis)
                
                neuron.dendritas.append(dendrita)
    
    def step(self):
        """
        Un paso de tiempo del autÃ³mata.
        Similar a red.procesar() en model/Red.js
        """
        # 1. Procesar todas las neuronas (excepto ENTRADA)
        for neuron in self.neuronas:
            if not isinstance(neuron, NeuronaEntrada):
                neuron.procesar()
        
        # 2. Activar neuronas
        for neuron in self.neuronas:
            neuron.activar()
        
        # 3. Entrenar sinapsis (si aprendizaje habilitado)
        if self.learning_enabled:
            for neuron in self.neuronas:
                neuron.entrenar()
        
        self.paso_actual += 1
    
    def set_input_region(self, values: np.ndarray):
        """
        Establece valores en la regiÃ³n de ENTRADA.
        values: Array 2D (H x W) o 1D que se mapea al ancho
        """
        entrada_neurons = [n for n in self.neuronas if n.region == config.REGIONES['ENTRADA']]
        
        if values.ndim == 1:
            # Vector 1D: Mapear a ancho de regiÃ³n ENTRADA
            for i, neuron in enumerate(entrada_neurons):
                if i < len(values):
                    neuron.set_valor(values[i])
        else:
            # Array 2D: Mapear directamente
            for neuron in entrada_neurons:
                if neuron.y < values.shape[0] and neuron.x < values.shape[1]:
                    neuron.set_valor(values[neuron.y, neuron.x])
    
    def get_output_region(self) -> np.ndarray:
        """Obtiene valores de la regiÃ³n de SALIDA"""
        salida_neurons = [n for n in self.neuronas if n.region == config.REGIONES['SALIDA']]
        salida_neurons.sort(key=lambda n: (n.y, n.x))
        return np.array([n.valor for n in salida_neurons])
    
    def get_state(self) -> np.ndarray:
        """Obtiene el estado completo del grid como array 2D"""
        state = np.zeros((self.height, self.width))
        for y in range(self.height):
            for x in range(self.width):
                state[y, x] = self.grid[y][x].valor
        return state
    
    def reset(self):
        """Resetea todas las neuronas"""
        for neuron in self.neuronas:
            neuron.reset()
        self.paso_actual = 0
```

### VisualizaciÃ³n

```python
# Celda 8: VisualizaciÃ³n con Matplotlib
def visualizar_cna(cna: ConnessionistNeuralAutomaton, figsize=(12, 10)):
    """
    Visualiza el estado del CNA con regiones coloreadas.
    """
    fig, axes = plt.subplots(2, 2, figsize=figsize)
    
    # 1. ActivaciÃ³n neuronal
    state = cna.get_state()
    im1 = axes[0, 0].imshow(state, cmap='hot', vmin=0, vmax=1)
    axes[0, 0].set_title(f'ActivaciÃ³n Neuronal (t={cna.paso_actual})')
    axes[0, 0].axis('off')
    plt.colorbar(im1, ax=axes[0, 0])
    
    # 2. Regiones
    regions = np.zeros((cna.height, cna.width))
    for y in range(cna.height):
        for x in range(cna.width):
            regions[y, x] = cna.grid[y][x].region
    
    im2 = axes[0, 1].imshow(regions, cmap='tab10', vmin=0, vmax=3)
    axes[0, 1].set_title('Regiones (ENTRADA=0, SALIDA=1, INTERNA=2, DOLOR=3)')
    axes[0, 1].axis('off')
    plt.colorbar(im2, ax=axes[0, 1], ticks=[0, 1, 2, 3])
    
    # 3. TensiÃ³n neuronal
    tension = np.zeros((cna.height, cna.width))
    for y in range(cna.height):
        for x in range(cna.width):
            tension[y, x] = cna.grid[y][x].tension
    
    im3 = axes[1, 0].imshow(tension, cmap='viridis', vmin=0, vmax=1)
    axes[1, 0].set_title('TensiÃ³n (Umbral dinÃ¡mico)')
    axes[1, 0].axis('off')
    plt.colorbar(im3, ax=axes[1, 0])
    
    # 4. Histograma de pesos sinÃ¡pticos
    pesos = []
    for neuron in cna.neuronas:
        for dendrita in neuron.dendritas:
            pesos.extend([s.peso for s in dendrita.sinapsis])
    
    axes[1, 1].hist(pesos, bins=50, color='steelblue', alpha=0.7)
    axes[1, 1].set_title(f'DistribuciÃ³n de Pesos SinÃ¡pticos (N={len(pesos)})')
    axes[1, 1].set_xlabel('Peso')
    axes[1, 1].set_ylabel('Frecuencia')
    
    plt.tight_layout()
    return fig

# Prueba inicial
print("Creando CNA de prueba 32x32...")
cna_test = ConnessionistNeuralAutomaton(32, 32, connect_radius=2)
print(f"Creado con {len(cna_test.neuronas)} neuronas")

# Contar sinapsis
total_sinapsis = sum(
    len(d.sinapsis) 
    for n in cna_test.neuronas 
    for d in n.dendritas
)
print(f"Total de sinapsis: {total_sinapsis}")

# Visualizar estado inicial
visualizar_cna(cna_test)
plt.show()
```

### Experimentos

```python
# Celda 9: Experimento 1 - PropagaciÃ³n de onda
def experimento_propagacion():
    """
    Activa una neurona central y observa cÃ³mo se propaga la activaciÃ³n.
    """
    print("=== Experimento 1: PropagaciÃ³n de Onda ===\n")
    
    cna = ConnessionistNeuralAutomaton(48, 48, connect_radius=3)
    
    # Activar neurona central
    center_x, center_y = cna.width // 2, cna.height // 2
    cna.grid[center_y][center_x].valor = 1.0
    cna.grid[center_y][center_x].activa = True
    
    # Deshabilitar aprendizaje para ver propagaciÃ³n pura
    cna.learning_enabled = False
    
    # Simular 20 pasos
    num_steps = 20
    states = [cna.get_state().copy()]
    
    for i in range(num_steps):
        cna.step()
        states.append(cna.get_state().copy())
    
    # Visualizar evoluciÃ³n
    fig, axes = plt.subplots(4, 5, figsize=(15, 12))
    axes = axes.flatten()
    
    for i, state in enumerate(states):
        im = axes[i].imshow(state, cmap='hot', vmin=0, vmax=1)
        axes[i].set_title(f't={i}')
        axes[i].axis('off')
    
    plt.suptitle('PropagaciÃ³n de Onda desde Centro', fontsize=16)
    plt.tight_layout()
    plt.show()
    
    return cna

experimento_propagacion()
```

```python
# Celda 10: Experimento 2 - Reflejo simple (sensor â†’ motor)
def experimento_reflejo():
    """
    Entrena un reflejo simple: sensor activo â†’ motor activo.
    Similar al reflejo de retracciÃ³n de Aplysia.
    """
    print("=== Experimento 2: Reflejo Simple ===\n")
    
    cna = ConnessionistNeuralAutomaton(32, 32, connect_radius=3)
    cna.learning_enabled = True
    
    # Entrenar: Activar sensores repetidamente
    num_epochs = 100
    activaciones_salida = []
    
    for epoch in range(num_epochs):
        # Reset
        cna.reset()
        
        # Activar toda la regiÃ³n ENTRADA
        input_pattern = np.ones(cna.width) * 0.8
        cna.set_input_region(input_pattern)
        
        # Propagar durante 10 pasos
        for _ in range(10):
            cna.step()
        
        # Medir activaciÃ³n en regiÃ³n SALIDA
        output = cna.get_output_region()
        activaciones_salida.append(output.mean())
    
    # Plot aprendizaje
    plt.figure(figsize=(10, 5))
    plt.plot(activaciones_salida, linewidth=2)
    plt.xlabel('Ã‰poca')
    plt.ylabel('ActivaciÃ³n media de regiÃ³n SALIDA')
    plt.title('Aprendizaje de Reflejo: Sensor â†’ Motor')
    plt.grid(True, alpha=0.3)
    plt.show()
    
    print(f"ActivaciÃ³n inicial: {activaciones_salida[0]:.4f}")
    print(f"ActivaciÃ³n final: {activaciones_salida[-1]:.4f}")
    print(f"Incremento: {activaciones_salida[-1] - activaciones_salida[0]:.4f}")
    
    # Visualizar estado final
    visualizar_cna(cna)
    plt.show()
    
    return cna

experimento_reflejo()
```

```python
# Celda 11: Experimento 3 - PatrÃ³n oscilante
def experimento_oscilador():
    """
    Busca patrones oscilantes emergentes (como en Game of Life).
    """
    print("=== Experimento 3: Patrones Oscilantes ===\n")
    
    cna = ConnessionistNeuralAutomaton(32, 32, connect_radius=2)
    cna.learning_enabled = False
    
    # Crear patrÃ³n inicial: Blinker vertical
    #   â—
    #   â—
    #   â—
    center_x, center_y = cna.width // 2, cna.height // 2
    for dy in [-1, 0, 1]:
        cna.grid[center_y + dy][center_x].valor = 1.0
    
    # Simular
    num_steps = 10
    states = []
    
    for i in range(num_steps):
        states.append(cna.get_state().copy())
        cna.step()
    
    # Detectar periodo
    def compare_states(s1, s2):
        return np.allclose(s1, s2, atol=0.1)
    
    periodo = None
    for i in range(1, len(states)):
        if compare_states(states[0], states[i]):
            periodo = i
            break
    
    # Visualizar
    fig, axes = plt.subplots(2, 5, figsize=(15, 6))
    axes = axes.flatten()
    
    for i, state in enumerate(states):
        im = axes[i].imshow(state, cmap='hot', vmin=0, vmax=1)
        axes[i].set_title(f't={i}')
        axes[i].axis('off')
    
    if periodo:
        plt.suptitle(f'Oscilador con Periodo {periodo}', fontsize=16)
    else:
        plt.suptitle('EvoluciÃ³n del PatrÃ³n', fontsize=16)
    
    plt.tight_layout()
    plt.show()
    
    return cna

experimento_oscilador()
```

### AnÃ¡lisis y MÃ©tricas

```python
# Celda 12: AnÃ¡lisis de conectividad
def analizar_conectividad(cna: ConnessionistNeuralAutomaton):
    """Analiza la estructura de conectividad del CNA"""
    
    print("=== AnÃ¡lisis de Conectividad ===\n")
    
    # Contar dendritas por neurona
    dendritas_por_neurona = [len(n.dendritas) for n in cna.neuronas if not isinstance(n, NeuronaEntrada)]
    
    # Contar sinapsis por dendrita
    sinapsis_por_dendrita = []
    for n in cna.neuronas:
        for d in n.dendritas:
            sinapsis_por_dendrita.append(len(d.sinapsis))
    
    # DistribuciÃ³n de pesos
    pesos = []
    for n in cna.neuronas:
        for d in n.dendritas:
            pesos.extend([s.peso for s in d.sinapsis])
    
    # Plot
    fig, axes = plt.subplots(1, 3, figsize=(15, 4))
    
    # 1. Dendritas por neurona
    axes[0].hist(dendritas_por_neurona, bins=10, color='steelblue', alpha=0.7)
    axes[0].set_title('Dendritas por Neurona')
    axes[0].set_xlabel('NÃºmero de dendritas')
    axes[0].set_ylabel('Frecuencia')
    axes[0].axvline(np.mean(dendritas_por_neurona), color='red', linestyle='--', 
                    label=f'Media: {np.mean(dendritas_por_neurona):.1f}')
    axes[0].legend()
    
    # 2. Sinapsis por dendrita
    axes[1].hist(sinapsis_por_dendrita, bins=15, color='seagreen', alpha=0.7)
    axes[1].set_title('Sinapsis por Dendrita')
    axes[1].set_xlabel('NÃºmero de sinapsis')
    axes[1].set_ylabel('Frecuencia')
    axes[1].axvline(np.mean(sinapsis_por_dendrita), color='red', linestyle='--',
                    label=f'Media: {np.mean(sinapsis_por_dendrita):.1f}')
    axes[1].legend()
    
    # 3. DistribuciÃ³n de pesos
    axes[2].hist(pesos, bins=50, color='coral', alpha=0.7)
    axes[2].set_title('DistribuciÃ³n de Pesos SinÃ¡pticos')
    axes[2].set_xlabel('Peso')
    axes[2].set_ylabel('Frecuencia')
    axes[2].axvline(np.mean(pesos), color='red', linestyle='--',
                    label=f'Media: {np.mean(pesos):.3f}')
    axes[2].legend()
    
    plt.tight_layout()
    plt.show()
    
    # EstadÃ­sticas
    print(f"Total de neuronas: {len(cna.neuronas)}")
    print(f"Total de dendritas: {sum(dendritas_por_neurona)}")
    print(f"Total de sinapsis: {len(pesos)}")
    print(f"\nDendritas por neurona: {np.mean(dendritas_por_neurona):.2f} Â± {np.std(dendritas_por_neurona):.2f}")
    print(f"Sinapsis por dendrita: {np.mean(sinapsis_por_dendrita):.2f} Â± {np.std(sinapsis_por_dendrita):.2f}")
    print(f"Peso sinÃ¡ptico medio: {np.mean(pesos):.4f} Â± {np.std(pesos):.4f}")
    print(f"\nSparsity: {(np.array(pesos) == 0).mean() * 100:.1f}% de sinapsis eliminadas (peso=0)")

# Analizar CNA de prueba
analizar_conectividad(cna_test)
```

### Guardar y Cargar

```python
# Celda 13: Guardar/cargar estado
import pickle

def guardar_cna(cna: ConnessionistNeuralAutomaton, filepath: str):
    """Guarda el estado completo del CNA"""
    with open(filepath, 'wb') as f:
        pickle.dump(cna, f)
    print(f"CNA guardado en: {filepath}")

def cargar_cna(filepath: str) -> ConnessionistNeuralAutomaton:
    """Carga un CNA guardado"""
    with open(filepath, 'rb') as f:
        cna = pickle.load(f)
    print(f"CNA cargado de: {filepath}")
    return cna

# Ejemplo
# guardar_cna(cna_test, "cna_estado.pkl")
# cna_cargado = cargar_cna("cna_estado.pkl")
```

### Resumen del Notebook 1

```markdown
## âœ… Logros del Notebook 1

1. **Clases base implementadas:**
   - `Sinapsis`: ConexiÃ³n pesada con aprendizaje Hebbiano
   - `Dendrita`: AgrupaciÃ³n de sinapsis (AND difuso)
   - `Neurona`: Unidad de procesamiento con tensiÃ³n dinÃ¡mica
   - `NeuronaEntrada`: Neurona sensorial

2. **AutÃ³mata celular:**
   - `ConnessionistNeuralAutomaton`: Grid 2D con regiones funcionales
   - Conectividad local (vecindad configurable)
   - MÃ©todo `step()` para evoluciÃ³n temporal

3. **Experimentos:**
   - PropagaciÃ³n de onda desde centro
   - Reflejo simple (aprendizaje sensorâ†’motor)
   - Patrones oscilantes

4. **VisualizaciÃ³n:**
   - Heatmaps de activaciÃ³n, tensiÃ³n, regiones
   - Histogramas de pesos sinÃ¡pticos
   - AnÃ¡lisis de conectividad

## ğŸš€ PrÃ³ximos Pasos (Notebook 2)

- Implementar **Self-Organizing Maps** (Kohonen)
- AÃ±adir **inhibiciÃ³n lateral** (sombrero mexicano)
- Experimentos de **clustering** espontÃ¡neo
- Visualizar mapas topolÃ³gicos emergentes
```

---

## ğŸ“˜ Notebook 2: Mapas Auto-Organizados (Kohonen)

### Objetivos

1. Implementar **Self-Organizing Map** (Kohonen)
2. FunciÃ³n **Mexican Hat** (sombrero mexicano) para inhibiciÃ³n lateral
3. **Clustering espontÃ¡neo** de patrones
4. Visualizar **mapas topolÃ³gicos** emergentes

### Concepto: Â¿QuÃ© es un SOM?

```
ENTRADA: Patrones de alta dimensiÃ³n
         â†“
    [Neurona 1][Neurona 2][Neurona 3]
    [Neurona 4][Neurona 5][Neurona 6]  â† Grid 2D
    [Neurona 7][Neurona 8][Neurona 9]
         â†“
SALIDA: RepresentaciÃ³n 2D donde patrones similares
        activan neuronas VECINAS (topologÃ­a preservada)
```

**Ejemplo biolÃ³gico:** Corteza auditiva tonotÃ³pica
- Frecuencias similares â†’ neuronas vecinas
- Mapa ordenado emerge del aprendizaje

### ImplementaciÃ³n

```python
# Celda 1: FunciÃ³n Mexican Hat
import numpy as np
import matplotlib.pyplot as plt

def mexican_hat(distance: float, sigma_excite: float = 1.0, sigma_inhibit: float = 3.0, 
                amplitude_excite: float = 1.0, amplitude_inhibit: float = 0.5) -> float:
    """
    FunciÃ³n de activaciÃ³n tipo sombrero mexicano.
    
    Args:
        distance: Distancia euclidiana desde el centro
        sigma_excite: Amplitud de la excitaciÃ³n central
        sigma_inhibit: Amplitud de la inhibiciÃ³n lateral
        amplitude_excite: Altura del pico de excitaciÃ³n
        amplitude_inhibit: Profundidad de la inhibiciÃ³n
    
    Returns:
        Valor de activaciÃ³n (positivo = excitaciÃ³n, negativo = inhibiciÃ³n)
    """
    # Componente de excitaciÃ³n (Gaussiana estrecha)
    excitation = amplitude_excite * np.exp(-distance**2 / (2 * sigma_excite**2))
    
    # Componente de inhibiciÃ³n (Gaussiana ancha)
    inhibition = amplitude_inhibit * np.exp(-distance**2 / (2 * sigma_inhibit**2))
    
    return excitation - inhibition

# Visualizar la funciÃ³n
distances = np.linspace(0, 10, 200)
activations = [mexican_hat(d) for d in distances]

plt.figure(figsize=(10, 6))
plt.plot(distances, activations, linewidth=3, color='darkblue')
plt.axhline(0, color='black', linestyle='--', linewidth=1)
plt.fill_between(distances, 0, activations, where=np.array(activations) > 0, 
                 color='green', alpha=0.3, label='ExcitaciÃ³n')
plt.fill_between(distances, 0, activations, where=np.array(activations) < 0, 
                 color='red', alpha=0.3, label='InhibiciÃ³n')
plt.xlabel('Distancia desde neurona ganadora', fontsize=12)
plt.ylabel('Efecto en neuronas vecinas', fontsize=12)
plt.title('FunciÃ³n Mexican Hat (Sombrero Mexicano)', fontsize=14, weight='bold')
plt.legend(fontsize=11)
plt.grid(True, alpha=0.3)
plt.show()
```

```python
# Celda 2: Clase KohonenSOM
class KohonenSOM:
    """
    Self-Organizing Map de Kohonen.
    Implementa clustering topolÃ³gico con Mexican Hat.
    """
    
    def __init__(self, map_size: Tuple[int, int], input_dim: int):
        """
        Args:
            map_size: (height, width) del mapa 2D
            input_dim: Dimensionalidad del input
        """
        self.height, self.width = map_size
        self.input_dim = input_dim
        
        # Pesos: Cada neurona tiene un vector de pesos de tamaÃ±o input_dim
        # InicializaciÃ³n aleatoria pequeÃ±a
        self.weights = np.random.randn(self.height, self.width, input_dim) * 0.1
        
        # Para visualizaciÃ³n
        self.activations = np.zeros((self.height, self.width))
        self.winner_history = []
    
    def find_winner(self, input_vector: np.ndarray) -> Tuple[int, int]:
        """
        Encuentra la neurona ganadora (BMU - Best Matching Unit).
        La neurona cuyos pesos estÃ¡n mÃ¡s cerca del input.
        """
        # Calcular distancia euclidiana de cada neurona al input
        distances = np.linalg.norm(self.weights - input_vector, axis=2)
        
        # Neurona con menor distancia
        winner_idx = np.unravel_index(np.argmin(distances), distances.shape)
        
        return winner_idx
    
    def get_neighborhood(self, winner: Tuple[int, int], radius: float) -> np.ndarray:
        """
        Calcula la funciÃ³n de vecindad (Mexican Hat).
        
        Returns:
            Array (H x W) con valores de influencia para cada neurona
        """
        wy, wx = winner
        
        # Crear grid de distancias
        y_grid, x_grid = np.meshgrid(np.arange(self.height), np.arange(self.width), indexing='ij')
        distances = np.sqrt((y_grid - wy)**2 + (x_grid - wx)**2)
        
        # Aplicar Mexican Hat
        neighborhood = np.vectorize(mexican_hat)(
            distances, 
            sigma_excite=radius, 
            sigma_inhibit=radius*2
        )
        
        return neighborhood
    
    def update(self, input_vector: np.ndarray, learning_rate: float, radius: float):
        """
        Actualiza los pesos segÃºn el algoritmo de Kohonen.
        """
        # 1. Encontrar ganador
        winner = self.find_winner(input_vector)
        self.winner_history.append(winner)
        
        # 2. Calcular funciÃ³n de vecindad
        neighborhood = self.get_neighborhood(winner, radius)
        
        # 3. Actualizar pesos
        # w_new = w_old + lr * neighborhood * (input - w_old)
        for i in range(self.height):
            for j in range(self.width):
                influence = neighborhood[i, j]
                if influence > 0:  # Solo actualizar si hay excitaciÃ³n
                    self.weights[i, j] += learning_rate * influence * (input_vector - self.weights[i, j])
    
    def train(self, data: np.ndarray, num_epochs: int, 
              initial_lr: float = 0.5, initial_radius: float = 3.0):
        """
        Entrena el SOM con un dataset.
        
        Args:
            data: Array (N x input_dim) con N ejemplos
            num_epochs: NÃºmero de Ã©pocas
            initial_lr: Learning rate inicial (decae con el tiempo)
            initial_radius: Radio de vecindad inicial (decae con el tiempo)
        """
        num_samples = len(data)
        
        for epoch in range(num_epochs):
            # Decaimiento exponencial
            lr = initial_lr * np.exp(-epoch / num_epochs)
            radius = initial_radius * np.exp(-epoch / num_epochs)
            
            # Presentar todos los ejemplos en orden aleatorio
            indices = np.random.permutation(num_samples)
            
            for idx in indices:
                input_vector = data[idx]
                self.update(input_vector, lr, radius)
            
            if (epoch + 1) % 10 == 0:
                print(f"Ã‰poca {epoch+1}/{num_epochs} - LR: {lr:.4f}, Radius: {radius:.2f}")
    
    def get_activation_map(self, input_vector: np.ndarray) -> np.ndarray:
        """Calcula un mapa de activaciÃ³n para un input especÃ­fico"""
        distances = np.linalg.norm(self.weights - input_vector, axis=2)
        # Convertir distancias a activaciones (mÃ¡s cerca = mÃ¡s activo)
        activations = np.exp(-distances / 2)
        return activations
    
    def visualize_weights(self, feature_names=None):
        """Visualiza los pesos de cada neurona"""
        fig, axes = plt.subplots(1, min(self.input_dim, 4), figsize=(15, 4))
        
        if self.input_dim == 1:
            axes = [axes]
        
        for i, ax in enumerate(axes):
            if i >= self.input_dim:
                break
            
            im = ax.imshow(self.weights[:, :, i], cmap='coolwarm')
            title = feature_names[i] if feature_names else f'Feature {i}'
            ax.set_title(title)
            ax.axis('off')
            plt.colorbar(im, ax=ax)
        
        plt.tight_layout()
        plt.show()
```

```python
# Celda 3: Experimento 1 - Clustering de colores RGB
def experimento_som_colores():
    """
    Entrenar SOM para organizar colores RGB en un mapa 2D.
    Resultado: Colores similares aparecerÃ¡n en regiones cercanas.
    """
    print("=== Experimento SOM: Clustering de Colores RGB ===\n")
    
    # Generar colores aleatorios (RGB normalizado)
    np.random.seed(42)
    num_colors = 500
    colors = np.random.rand(num_colors, 3)  # [R, G, B] en [0, 1]
    
    # Crear y entrenar SOM
    som = KohonenSOM(map_size=(20, 20), input_dim=3)
    som.train(colors, num_epochs=100, initial_lr=0.5, initial_radius=5.0)
    
    # Visualizar mapa de colores aprendido
    plt.figure(figsize=(12, 10))
    
    # Crear imagen RGB desde los pesos
    color_map = som.weights.copy()
    color_map = np.clip(color_map, 0, 1)  # Asegurar rango [0,1]
    
    plt.imshow(color_map)
    plt.title('Mapa Auto-Organizado de Colores RGB', fontsize=14, weight='bold')
    plt.axis('off')
    
    # AÃ±adir grid para ver cÃ©lulas
    for i in range(som.height + 1):
        plt.axhline(i - 0.5, color='white', linewidth=0.5, alpha=0.5)
    for j in range(som.width + 1):
        plt.axvline(j - 0.5, color='white', linewidth=0.5, alpha=0.5)
    
    plt.tight_layout()
    plt.show()
    
    # Visualizar activaciÃ³n para colores especÃ­ficos
    test_colors = [
        ([1, 0, 0], "Rojo"),
        ([0, 1, 0], "Verde"),
        ([0, 0, 1], "Azul"),
        ([1, 1, 0], "Amarillo")
    ]
    
    fig, axes = plt.subplots(2, 2, figsize=(12, 12))
    axes = axes.flatten()
    
    for idx, (color, name) in enumerate(test_colors):
        activation = som.get_activation_map(np.array(color))
        
        im = axes[idx].imshow(activation, cmap='hot')
        axes[idx].set_title(f'ActivaciÃ³n para {name} {color}', fontsize=12)
        axes[idx].axis('off')
        plt.colorbar(im, ax=axes[idx])
    
    plt.tight_layout()
    plt.show()
    
    return som

som_colores = experimento_som_colores()
```

```python
# Celda 4: Integrar SOM con CNA
class CNA_ConSOM(ConnessionistNeuralAutomaton):
    """
    CNA con capacidades de Self-Organization (Kohonen).
    AÃ±ade inhibiciÃ³n lateral tipo Mexican Hat.
    """
    
    def __init__(self, width: int = 64, height: int = 64):
        super().__init__(width, height, connect_radius=3)
        
        # AÃ±adir dendritas laterales (para inhibiciÃ³n/excitaciÃ³n)
        self.add_lateral_connections()
    
    def add_lateral_connections(self):
        """
        AÃ±ade conexiones laterales a cada neurona segÃºn Mexican Hat.
        """
        for neuron in self.neuronas:
            if isinstance(neuron, NeuronaEntrada):
                continue
            
            # Crear dendrita lateral
            dendrita_lateral = Dendrita()
            
            # Conectar con vecinos en radio amplio
            neighbors = self.get_neighbors(neuron, radius=5)
            
            for neighbor in neighbors:
                # Calcular distancia
                dx = neighbor.x - neuron.x
                dy = neighbor.y - neuron.y
                distance = np.sqrt(dx**2 + dy**2)
                
                # Peso segÃºn Mexican Hat
                weight = mexican_hat(distance, sigma_excite=1.5, sigma_inhibit=3.0)
                
                # Crear sinapsis (puede ser negativa para inhibiciÃ³n)
                sinapsis = Sinapsis(neighbor, peso=abs(weight))
                sinapsis.inhibitoria = weight < 0  # Marcar como inhibitoria
                
                dendrita_lateral.agregar_sinapsis(sinapsis)
            
            neuron.dendritas.append(dendrita_lateral)
    
    def step_with_lateral(self):
        """Step con inhibiciÃ³n lateral explÃ­cita"""
        # Paso normal
        self.step()
        
        # Aplicar inhibiciÃ³n lateral adicional
        for neuron in self.neuronas:
            if isinstance(neuron, NeuronaEntrada):
                continue
            
            # Calcular efecto lateral
            lateral_effect = 0.0
            for dendrita in neuron.dendritas:
                for sinapsis in dendrita.sinapsis:
                    effect = sinapsis.procesar()
                    if hasattr(sinapsis, 'inhibitoria') and sinapsis.inhibitoria:
                        lateral_effect -= effect
                    else:
                        lateral_effect += effect
            
            # Modular valor
            neuron.valor = max(0.0, min(1.0, neuron.valor + lateral_effect * 0.1))

# AÃ±adir atributo inhibitoria a Sinapsis existente
Sinapsis.inhibitoria = False
```

```python
# Celda 5: Experimento 2 - Clustering espontÃ¡neo en CNA
def experimento_clustering_espacial():
    """
    Mostrar cÃ³mo emergen clusters en el CNA con inhibiciÃ³n lateral.
    """
    print("=== Experimento: Clustering Espacial con Mexican Hat ===\n")
    
    cna = CNA_ConSOM(32, 32)
    cna.learning_enabled = False
    
    # Activar puntos aleatorios en regiÃ³n ENTRADA
    num_puntos = 50
    for _ in range(num_puntos):
        x = random.randint(0, cna.width - 1)
        y = random.randint(0, min(15, cna.height // 4))  # RegiÃ³n ENTRADA
        cna.grid[y][x].valor = random.uniform(0.5, 1.0)
    
    # Simular con inhibiciÃ³n lateral
    num_steps = 30
    states = []
    
    for i in range(num_steps):
        states.append(cna.get_state().copy())
        cna.step_with_lateral()
    
    # Visualizar evoluciÃ³n (muestrear cada 5 pasos)
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    axes = axes.flatten()
    
    sample_steps = [0, 5, 10, 15, 20, 29]
    
    for idx, step in enumerate(sample_steps):
        im = axes[idx].imshow(states[step], cmap='hot', vmin=0, vmax=1)
        axes[idx].set_title(f't={step}', fontsize=12)
        axes[idx].axis('off')
        plt.colorbar(im, ax=axes[idx])
    
    plt.suptitle('Clustering EspontÃ¡neo con InhibiciÃ³n Lateral', fontsize=16, weight='bold')
    plt.tight_layout()
    plt.show()
    
    print("Observa cÃ³mo:")
    print("1. Activaciones iniciales dispersas")
    print("2. InhibiciÃ³n lateral suprime vecinos")
    print("3. Emergen 'winner-take-all' clusters")
    print("4. Solo las neuronas mÃ¡s fuertes sobreviven")
    
    return cna

experimento_clustering_espacial()
```

```python
# Celda 6: Experimento 3 - Mapeo tonotÃ³pico (frecuencias)
def experimento_mapa_tonotopico():
    """
    Simula cÃ³mo la corteza auditiva crea mapas de frecuencias.
    Frecuencias similares â†’ neuronas vecinas.
    """
    print("=== Experimento: Mapa TonotÃ³pico (Frecuencias) ===\n")
    
    # Generar tonos de diferentes frecuencias
    num_frequencies = 50
    frequencies = np.linspace(100, 1000, num_frequencies)  # 100 Hz a 1000 Hz
    
    # Crear representaciones de frecuencia (one-hot like, pero suavizado)
    def frequency_to_vector(freq, all_freqs):
        # Gaussiana centrada en la frecuencia
        sigma = 50
        vector = np.exp(-((all_freqs - freq)**2) / (2 * sigma**2))
        return vector / vector.sum()
    
    freq_vectors = np.array([frequency_to_vector(f, frequencies) for f in frequencies])
    
    # Entrenar SOM
    som = KohonenSOM(map_size=(10, 50), input_dim=num_frequencies)
    som.train(freq_vectors, num_epochs=100, initial_lr=0.3, initial_radius=8.0)
    
    # Visualizar mapa tonotÃ³pico
    # Para cada posiciÃ³n del SOM, encontrar quÃ© frecuencia responde mejor
    freq_map = np.zeros((som.height, som.width))
    
    for i in range(som.height):
        for j in range(som.width):
            # Pesos de esta neurona
            weights = som.weights[i, j]
            # Frecuencia con mayor peso
            best_freq_idx = np.argmax(weights)
            freq_map[i, j] = frequencies[best_freq_idx]
    
    # Plot
    plt.figure(figsize=(16, 6))
    
    im = plt.imshow(freq_map, cmap='viridis', aspect='auto')
    plt.colorbar(im, label='Frecuencia (Hz)')
    plt.title('Mapa TonotÃ³pico Auto-Organizado\n(Similar a la corteza auditiva primaria)', 
              fontsize=14, weight='bold')
    plt.xlabel('PosiciÃ³n X en el mapa')
    plt.ylabel('PosiciÃ³n Y en el mapa')
    
    # Overlay: Marcar algunas frecuencias especÃ­ficas
    test_freqs = [200, 400, 600, 800]
    for freq in test_freqs:
        activation = som.get_activation_map(frequency_to_vector(freq, frequencies))
        max_pos = np.unravel_index(np.argmax(activation), activation.shape)
        plt.plot(max_pos[1], max_pos[0], 'ro', markersize=10, 
                markeredgecolor='white', markeredgewidth=2)
        plt.text(max_pos[1], max_pos[0] - 1, f'{freq}Hz', 
                color='white', fontsize=10, ha='center', weight='bold')
    
    plt.tight_layout()
    plt.show()
    
    print("Observa:")
    print("- Frecuencias bajas (azul) â†’ un extremo del mapa")
    print("- Frecuencias altas (amarillo) â†’ otro extremo")
    print("- TopologÃ­a preservada: Frecuencias vecinas â†’ Neuronas vecinas")
    print("- Â¡Como en el cerebro real!")
    
    return som

experimento_mapa_tonotopico()
```

### Resumen del Notebook 2

```markdown
## âœ… Logros del Notebook 2

1. **Self-Organizing Map (Kohonen):**
   - ImplementaciÃ³n completa de SOM
   - Winner-take-all competitivo
   - Decaimiento de learning rate y radio

2. **Mexican Hat Function:**
   - InhibiciÃ³n lateral + excitaciÃ³n central
   - Emergencia de clusters espaciales

3. **IntegraciÃ³n con CNA:**
   - `CNA_ConSOM`: AutÃ³mata con conexiones laterales
   - InhibiciÃ³n/excitaciÃ³n basada en distancia

4. **Experimentos:**
   - Clustering de colores RGB
   - Clustering espacial en grid 2D
   - Mapa tonotÃ³pico (frecuencias)

5. **Aprendizajes biolÃ³gicos:**
   - Mapas topolÃ³gicos emergen espontÃ¡neamente
   - Competencia neuronal â†’ especializaciÃ³n
   - PreservaciÃ³n de topologÃ­a del input

## ğŸš€ PrÃ³ximos Pasos (Notebook 3)

- Implementar **Hierarchical Temporal Memory** (Hawkins)
- Aprendizaje de **secuencias temporales**
- **PredicciÃ³n** del siguiente estado
- **Memory replay** sin input externo
```

---

## ğŸ“˜ Notebook 3: Memoria Temporal y PredicciÃ³n (HTM)

### Objetivos

1. Implementar **Temporal Memory** (secuencias)
2. **PredicciÃ³n** del siguiente estado
3. **Sparse Distributed Representations** (SDR)
4. **Memory replay** (reproducir secuencias aprendidas)
5. Integrar con **place cells** y **grid cells**

### Concepto: Hierarchical Temporal Memory

Jeff Hawkins propone que el neocÃ³rtex funciona como:

```
Nivel 3: [Conceptos abstractos]
              â†“ predice
Nivel 2: [Secuencias de patrones]
              â†“ predice
Nivel 1: [Patrones sensoriales]
              â†“
        [Input sensorial]
```

**Principios clave:**

1. **Sparse activation:** Solo ~2% de neuronas activas simultÃ¡neamente
2. **Sequence learning:** Aâ†’Bâ†’C se aprende como pares (A,B), (B,C)
3. **Prediction:** Si veo A, pre-activo neuronas de B (estado predictivo)
4. **Surprise:** Si predicciÃ³n falla â†’ aprendizaje fuerte

### ImplementaciÃ³n

```python
# Celda 1: Sparse Distributed Representation
class SDR:
    """
    Sparse Distributed Representation.
    Solo un pequeÃ±o % de bits estÃ¡n activos.
    """
    
    def __init__(self, size: int, sparsity: float = 0.02):
        """
        Args:
            size: NÃºmero total de bits
            sparsity: FracciÃ³n de bits activos (ej: 0.02 = 2%)
        """
        self.size = size
        self.sparsity = sparsity
        self.num_active = int(size * sparsity)
        self.active_indices = set()
    
    def set_random(self):
        """Activa bits aleatorios"""
        self.active_indices = set(np.random.choice(
            self.size, 
            size=self.num_active, 
            replace=False
        ))
    
    def set_from_pattern(self, pattern: np.ndarray):
        """
        Convierte un patrÃ³n denso a SDR.
        Activa los k bits con mayor valor.
        """
        # Ordenar por valor y tomar top-k
        top_indices = np.argsort(pattern)[-self.num_active:]
        self.active_indices = set(top_indices)
    
    def to_dense(self) -> np.ndarray:
        """Convierte a representaciÃ³n densa (array de 0s y 1s)"""
        dense = np.zeros(self.size)
        for idx in self.active_indices:
            dense[idx] = 1
        return dense
    
    def overlap(self, other: 'SDR') -> float:
        """
        Calcula overlap con otro SDR.
        Overlap = |A âˆ© B| / |A âˆª B|
        """
        intersection = len(self.active_indices & other.active_indices)
        union = len(self.active_indices | other.active_indices)
        return intersection / union if union > 0 else 0.0
    
    def __repr__(self):
        return f"SDR(size={self.size}, active={len(self.active_indices)}, sparsity={len(self.active_indices)/self.size:.2%})"

# Ejemplo
sdr1 = SDR(size=2048, sparsity=0.02)
sdr1.set_random()

sdr2 = SDR(size=2048, sparsity=0.02)
sdr2.set_random()

print(f"SDR 1: {sdr1}")
print(f"SDR 2: {sdr2}")
print(f"Overlap: {sdr1.overlap(sdr2):.4f}")  # DeberÃ­a ser bajo (~0 para SDRs aleatorios)
```

```python
# Celda 2: Temporal Memory
class TemporalMemory:
    """
    Memoria temporal que aprende secuencias.
    ImplementaciÃ³n simplificada de HTM.
    """
    
    def __init__(self, num_columns: int, cells_per_column: int = 32):
        """
        Args:
            num_columns: NÃºmero de columnas (mini-columns) corticales
            cells_per_column: CÃ©lulas por columna
        """
        self.num_columns = num_columns
        self.cells_per_column = cells_per_column
        self.total_cells = num_columns * cells_per_column
        
        # Estado de las cÃ©lulas
        self.active_cells = set()       # CÃ©lulas actualmente activas
        self.predictive_cells = set()   # CÃ©lulas en estado predictivo
        self.winner_cells = set()       # CÃ©lulas ganadoras (para aprendizaje)
        
        # Conexiones dendrÃ­ticas
        # connections[cell] = {prev_cell1: permanence1, prev_cell2: permanence2, ...}
        self.connections = {i: {} for i in range(self.total_cells)}
        
        # HiperparÃ¡metros
        self.initial_permanence = 0.21
        self.connected_permanence = 0.50
        self.permanence_increment = 0.10
        self.permanence_decrement = 0.10
        self.activation_threshold = 13  # MÃ­nimo de conexiones activas para predecir
        
        # Para visualizaciÃ³n
        self.history_active = []
        self.history_predictive = []
    
    def reset(self):
        """Resetea el estado (sin olvidar conexiones aprendidas)"""
        self.active_cells.clear()
        self.predictive_cells.clear()
        self.winner_cells.clear()
    
    def compute(self, active_columns: set, learn: bool = True):
        """
        Procesa un paso de tiempo.
        
        Args:
            active_columns: Conjunto de columnas activas en este paso
            learn: Si True, actualiza conexiones sinÃ¡pticas
        """
        # 1. Activar cÃ©lulas
        prev_predictive = self.predictive_cells.copy()
        self.active_cells.clear()
        self.winner_cells.clear()
        
        for column in active_columns:
            # Verificar si habÃ­a predicciÃ³n correcta
            predicted_cells_in_column = [
                c for c in prev_predictive 
                if c // self.cells_per_column == column
            ]
            
            if predicted_cells_in_column:
                # PredicciÃ³n correcta: activar cÃ©lulas predictivas
                self.active_cells.update(predicted_cells_in_column)
                self.winner_cells.update(predicted_cells_in_column[:1])  # Una ganadora
            else:
                # Sin predicciÃ³n: activar todas las cÃ©lulas de la columna (bursting)
                start_idx = column * self.cells_per_column
                cells_in_column = list(range(start_idx, start_idx + self.cells_per_column))
                self.active_cells.update(cells_in_column)
                # Escoger una cÃ©lula ganadora aleatoria
                self.winner_cells.add(random.choice(cells_in_column))
        
        # 2. Predecir siguiente paso
        self.predictive_cells.clear()
        
        for cell in range(self.total_cells):
            # Contar cuÃ¡ntas conexiones activas tiene esta cÃ©lula
            active_connections = sum(
                1 for prev_cell, perm in self.connections[cell].items()
                if prev_cell in self.active_cells and perm >= self.connected_permanence
            )
            
            # Si supera umbral, poner en estado predictivo
            if active_connections >= self.activation_threshold:
                self.predictive_cells.add(cell)
        
        # 3. Aprender conexiones (si habilitado)
        if learn:
            for winner_cell in self.winner_cells:
                # Reforzar conexiones con cÃ©lulas activas en el paso anterior
                for prev_cell in self.active_cells:
                    if prev_cell in self.connections[winner_cell]:
                        # Incrementar permanencia de conexiÃ³n existente
                        self.connections[winner_cell][prev_cell] += self.permanence_increment
                        self.connections[winner_cell][prev_cell] = min(1.0, self.connections[winner_cell][prev_cell])
                    else:
                        # Crear nueva conexiÃ³n
                        if len(self.connections[winner_cell]) < 100:  # LÃ­mite de conexiones por cÃ©lula
                            self.connections[winner_cell][prev_cell] = self.initial_permanence
                
                # Debilitar conexiones con cÃ©lulas inactivas
                for prev_cell in list(self.connections[winner_cell].keys()):
                    if prev_cell not in self.active_cells:
                        self.connections[winner_cell][prev_cell] -= self.permanence_decrement
                        # Eliminar si permanencia cae por debajo de 0
                        if self.connections[winner_cell][prev_cell] <= 0:
                            del self.connections[winner_cell][prev_cell]
        
        # Guardar historial
        self.history_active.append(self.active_cells.copy())
        self.history_predictive.append(self.predictive_cells.copy())
    
    def get_active_columns(self) -> set:
        """Obtiene columnas activas"""
        return {cell // self.cells_per_column for cell in self.active_cells}
    
    def get_predictive_columns(self) -> set:
        """Obtiene columnas en estado predictivo"""
        return {cell // self.cells_per_column for cell in self.predictive_cells}
    
    def visualize_state(self, step: int):
        """Visualiza el estado de las cÃ©lulas"""
        # Crear matriz (columnas x cÃ©lulas_por_columna)
        state = np.zeros((self.num_columns, self.cells_per_column))
        
        for cell in self.active_cells:
            col = cell // self.cells_per_column
            cell_in_col = cell % self.cells_per_column
            state[col, cell_in_col] = 1.0  # Activa
        
        for cell in self.predictive_cells:
            col = cell // self.cells_per_column
            cell_in_col = cell % self.cells_per_column
            if cell not in self.active_cells:
                state[col, cell_in_col] = 0.5  # Predictiva
        
        plt.figure(figsize=(12, 4))
        plt.imshow(state.T, cmap='RdYlGn', aspect='auto', vmin=0, vmax=1)
        plt.colorbar(label='Estado', ticks=[0, 0.5, 1.0], 
                     format=plt.FuncFormatter(lambda x, p: ['Inactiva', 'Predictiva', 'Activa'][int(x*2)]))
        plt.xlabel('Columna')
        plt.ylabel('CÃ©lula dentro de columna')
        plt.title(f'Estado de Memoria Temporal (t={step})', fontsize=12, weight='bold')
        plt.tight_layout()
        plt.show()
```

```python
# Celda 3: Experimento 1 - Aprender secuencia simple
def experimento_secuencia_simple():
    """
    Aprender la secuencia: A â†’ B â†’ C â†’ D â†’ A â†’ ...
    """
    print("=== Experimento: Aprender Secuencia Aâ†’Bâ†’Câ†’D ===\n")
    
    # Crear TM con 100 columnas
    tm = TemporalMemory(num_columns=100, cells_per_column=32)
    
    # Definir patrones (conjuntos de columnas activas)
    patterns = {
        'A': set(range(0, 20)),      # Columnas 0-19
        'B': set(range(20, 40)),     # Columnas 20-39
        'C': set(range(40, 60)),     # Columnas 40-59
        'D': set(range(60, 80)),     # Columnas 60-79
    }
    
    sequence = ['A', 'B', 'C', 'D']
    
    # Entrenar
    num_epochs = 10
    prediction_accuracy = []
    
    for epoch in range(num_epochs):
        tm.reset()
        correct_predictions = 0
        total_predictions = 0
        
        for i in range(len(sequence) * 5):  # Repetir secuencia 5 veces por Ã©poca
            pattern_name = sequence[i % len(sequence)]
            active_columns = patterns[pattern_name]
            
            # Verificar predicciÃ³n (antes de procesar)
            if i > 0:
                predicted_cols = tm.get_predictive_columns()
                if predicted_cols == active_columns:
                    correct_predictions += 1
                total_predictions += 1
            
            # Procesar
            tm.compute(active_columns, learn=True)
        
        accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0
        prediction_accuracy.append(accuracy)
        print(f"Ã‰poca {epoch+1}: PrecisiÃ³n de predicciÃ³n = {accuracy:.2%}")
    
    # Visualizar aprendizaje
    plt.figure(figsize=(10, 5))
    plt.plot(range(1, num_epochs+1), prediction_accuracy, marker='o', linewidth=2, markersize=8)
    plt.xlabel('Ã‰poca')
    plt.ylabel('PrecisiÃ³n de PredicciÃ³n')
    plt.title('Aprendizaje de Secuencia Temporal', fontsize=14, weight='bold')
    plt.grid(True, alpha=0.3)
    plt.ylim([0, 1.05])
    plt.show()
    
    # Test: Mostrar predicciones
    print("\n--- Test de PredicciÃ³n ---")
    tm.reset()
    
    for i, pattern_name in enumerate(sequence):
        print(f"\nPaso {i+1}: Input = {pattern_name}")
        
        # Mostrar predicciÃ³n ANTES de dar el input
        if i > 0:
            predicted_cols = tm.get_predictive_columns()
            # Identificar quÃ© patrÃ³n se predijo
            for pname, pcols in patterns.items():
                if predicted_cols == pcols:
                    print(f"  â†’ PredicciÃ³n: {pname} âœ“")
                    break
            else:
                print(f"  â†’ PredicciÃ³n: Desconocido (cols={predicted_cols})")
        
        # Procesar input
        tm.compute(patterns[pattern_name], learn=False)
        tm.visualize_state(i)
    
    return tm

experimento_secuencia_simple()
```

```python
# Celda 4: Place Cells y Grid Cells
class PlaceCell:
    """
    CÃ©lula de lugar (place cell).
    Se activa cuando el agente estÃ¡ en una posiciÃ³n especÃ­fica.
    """
    
    def __init__(self, preferred_location: Tuple[float, float], radius: float = 2.0):
        """
        Args:
            preferred_location: (x, y) posiciÃ³n preferida
            radius: Radio de activaciÃ³n
        """
        self.preferred_x, self.preferred_y = preferred_location
        self.radius = radius
        self.activation = 0.0
        self.history = []
    
    def compute_activation(self, current_location: Tuple[float, float]) -> float:
        """
        Calcula activaciÃ³n segÃºn distancia a posiciÃ³n preferida.
        ActivaciÃ³n = Gaussiana centrada en preferred_location
        """
        x, y = current_location
        distance = np.sqrt((x - self.preferred_x)**2 + (y - self.preferred_y)**2)
        
        # Gaussiana
        self.activation = np.exp(-distance**2 / (2 * self.radius**2))
        self.history.append(self.activation)
        
        return self.activation


class GridCell:
    """
    CÃ©lula de grilla (grid cell).
    Se activa en mÃºltiples posiciones formando un patrÃ³n hexagonal.
    """
    
    def __init__(self, spacing: float = 5.0, orientation: float = 0.0, phase: Tuple[float, float] = (0, 0)):
        """
        Args:
            spacing: Espaciado entre picos de activaciÃ³n
            orientation: OrientaciÃ³n del grid (radianes)
            phase: Desplazamiento de fase (x, y)
        """
        self.spacing = spacing
        self.orientation = orientation
        self.phase_x, self.phase_y = phase
        self.activation = 0.0
        self.history = []
    
    def compute_activation(self, current_location: Tuple[float, float]) -> float:
        """
        Calcula activaciÃ³n en patrÃ³n hexagonal.
        Usa suma de 3 ondas sinusoidales con orientaciones 60Â° aparte.
        """
        x, y = current_location
        
        # Aplicar fase
        x = x - self.phase_x
        y = y - self.phase_y
        
        # 3 ondas sinusoidales con 60Â° de separaciÃ³n
        angles = [self.orientation, self.orientation + np.pi/3, self.orientation + 2*np.pi/3]
        
        wave_sum = 0
        for angle in angles:
            # Proyectar posiciÃ³n en direcciÃ³n de la onda
            projection = x * np.cos(angle) + y * np.sin(angle)
            wave_sum += np.cos(2 * np.pi * projection / self.spacing)
        
        # Normalizar y aplicar umbral
        self.activation = max(0, (wave_sum + 1.5) / 4.5)  # Mapear a [0, 1]
        self.history.append(self.activation)
        
        return self.activation


class SpatialNavigationSystem:
    """
    Sistema de navegaciÃ³n espacial con place cells y grid cells.
    """
    
    def __init__(self, world_size: Tuple[int, int] = (20, 20)):
        self.world_width, self.world_height = world_size
        self.current_position = (world_size[0] / 2, world_size[1] / 2)
        
        # Crear place cells distribuidas uniformemente
        self.place_cells = []
        spacing = 3
        for x in range(0, world_size[0], spacing):
            for y in range(0, world_size[1], spacing):
                pc = PlaceCell((x, y), radius=2.0)
                self.place_cells.append(pc)
        
        # Crear grid cells con diferentes escalas
        self.grid_cells = []
        spacings = [3, 5, 7]  # Diferentes escalas
        for spacing in spacings:
            for phase_x in [0, spacing/2]:
                for phase_y in [0, spacing/2]:
                    gc = GridCell(spacing=spacing, orientation=0, phase=(phase_x, phase_y))
                    self.grid_cells.append(gc)
        
        print(f"Creado sistema con {len(self.place_cells)} place cells y {len(self.grid_cells)} grid cells")
    
    def move_to(self, new_position: Tuple[float, float]):
        """Mueve el agente a una nueva posiciÃ³n y actualiza cÃ©lulas"""
        self.current_position = new_position
        
        # Actualizar place cells
        for pc in self.place_cells:
            pc.compute_activation(new_position)
        
        # Actualizar grid cells
        for gc in self.grid_cells:
            gc.compute_activation(new_position)
    
    def get_place_field_map(self) -> np.ndarray:
        """Crea mapa de activaciÃ³n de place cells"""
        map_resolution = 50
        place_map = np.zeros((map_resolution, map_resolution))
        
        for i in range(map_resolution):
            for j in range(map_resolution):
                x = (i / map_resolution) * self.world_width
                y = (j / map_resolution) * self.world_height
                
                # Sumar activaciÃ³n de todas las place cells
                total_activation = 0
                for pc in self.place_cells:
                    dist = np.sqrt((x - pc.preferred_x)**2 + (y - pc.preferred_y)**2)
                    activation = np.exp(-dist**2 / (2 * pc.radius**2))
                    total_activation += activation
                
                place_map[j, i] = total_activation
        
        return place_map
    
    def get_grid_field_map(self, grid_cell_idx: int = 0) -> np.ndarray:
        """Crea mapa de activaciÃ³n de una grid cell especÃ­fica"""
        map_resolution = 100
        grid_map = np.zeros((map_resolution, map_resolution))
        
        gc = self.grid_cells[grid_cell_idx]
        
        for i in range(map_resolution):
            for j in range(map_resolution):
                x = (i / map_resolution) * self.world_width
                y = (j / map_resolution) * self.world_height
                
                # Calcular activaciÃ³n
                x_shifted = x - gc.phase_x
                y_shifted = y - gc.phase_y
                
                angles = [gc.orientation, gc.orientation + np.pi/3, gc.orientation + 2*np.pi/3]
                wave_sum = 0
                for angle in angles:
                    projection = x_shifted * np.cos(angle) + y_shifted * np.sin(angle)
                    wave_sum += np.cos(2 * np.pi * projection / gc.spacing)
                
                grid_map[j, i] = max(0, (wave_sum + 1.5) / 4.5)
        
        return grid_map
```

```python
# Celda 5: Experimento 2 - NavegaciÃ³n con place cells
def experimento_place_cells():
    """
    Simula un agente navegando y activa place cells.
    """
    print("=== Experimento: Place Cells y Grid Cells ===\n")
    
    nav_system = SpatialNavigationSystem(world_size=(20, 20))
    
    # Simular trayectoria: Cuadrado
    trajectory = []
    positions = [
        (5, 5), (15, 5), (15, 15), (5, 15), (5, 5)
    ]
    
    # Interpolar entre posiciones
    for i in range(len(positions) - 1):
        start = positions[i]
        end = positions[i + 1]
        steps = 20
        
        for t in range(steps):
            alpha = t / steps
            x = start[0] + alpha * (end[0] - start[0])
            y = start[1] + alpha * (end[1] - start[1])
            trajectory.append((x, y))
            nav_system.move_to((x, y))
    
    # Visualizar
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    
    # 1. Trayectoria
    traj_array = np.array(trajectory)
    axes[0, 0].plot(traj_array[:, 0], traj_array[:, 1], 'b-', linewidth=2)
    axes[0, 0].plot(traj_array[0, 0], traj_array[0, 1], 'go', markersize=15, label='Start')
    axes[0, 0].plot(traj_array[-1, 0], traj_array[-1, 1], 'ro', markersize=15, label='End')
    axes[0, 0].set_xlim([0, 20])
    axes[0, 0].set_ylim([0, 20])
    axes[0, 0].set_title('Trayectoria del Agente', fontsize=12, weight='bold')
    axes[0, 0].set_xlabel('X')
    axes[0, 0].set_ylabel('Y')
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)
    
    # 2. Mapa de place cells
    place_map = nav_system.get_place_field_map()
    im1 = axes[0, 1].imshow(place_map, cmap='hot', origin='lower', extent=[0, 20, 0, 20])
    axes[0, 1].plot(traj_array[:, 0], traj_array[:, 1], 'c-', linewidth=2, alpha=0.5)
    axes[0, 1].set_title('Place Fields (Cobertura)', fontsize=12, weight='bold')
    axes[0, 1].set_xlabel('X')
    axes[0, 1].set_ylabel('Y')
    plt.colorbar(im1, ax=axes[0, 1])
    
    # 3-5. Grid cells (diferentes escalas)
    for idx in range(3):
        grid_map = nav_system.get_grid_field_map(grid_cell_idx=idx*4)
        im = axes[0 if idx < 2 else 1, 2 if idx == 0 else (0 if idx == 1 else 1)].imshow(
            grid_map, cmap='viridis', origin='lower', extent=[0, 20, 0, 20]
        )
        axes[0 if idx < 2 else 1, 2 if idx == 0 else (0 if idx == 1 else 1)].plot(
            traj_array[:, 0], traj_array[:, 1], 'r-', linewidth=1.5, alpha=0.5
        )
        axes[0 if idx < 2 else 1, 2 if idx == 0 else (0 if idx == 1 else 1)].set_title(
            f'Grid Cell {idx+1} (spacing={nav_system.grid_cells[idx*4].spacing})', 
            fontsize=11, weight='bold'
        )
        axes[0 if idx < 2 else 1, 2 if idx == 0 else (0 if idx == 1 else 1)].set_xlabel('X')
        axes[0 if idx < 2 else 1, 2 if idx == 0 else (0 if idx == 1 else 1)].set_ylabel('Y')
        plt.colorbar(im, ax=axes[0 if idx < 2 else 1, 2 if idx == 0 else (0 if idx == 1 else 1)])
    
    # 6. ActivaciÃ³n temporal de place cells
    # Seleccionar 5 place cells representativas
    selected_pcs = [nav_system.place_cells[i] for i in [0, 10, 20, 30, 40]]
    
    for i, pc in enumerate(selected_pcs):
        axes[1, 2].plot(pc.history, label=f'PC {i+1} @ ({pc.preferred_x:.1f},{pc.preferred_y:.1f})')
    
    axes[1, 2].set_xlabel('Paso de tiempo')
    axes[1, 2].set_ylabel('ActivaciÃ³n')
    axes[1, 2].set_title('ActivaciÃ³n Temporal de Place Cells', fontsize=11, weight='bold')
    axes[1, 2].legend(fontsize=8)
    axes[1, 2].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    print("Observa:")
    print("1. Place cells: ActivaciÃ³n localizada en posiciones especÃ­ficas")
    print("2. Grid cells: PatrÃ³n hexagonal que cubre todo el espacio")
    print("3. ActivaciÃ³n temporal: Cada place cell 'dispara' cuando el agente pasa por su zona")
    print("4. Grid cells con diferentes escalas cubren distintas resoluciones espaciales")
    
    return nav_system

experimento_place_cells()
```

```python
# Celda 6: Memory Replay
def experimento_memory_replay():
    """
    Simula memory replay: Reproducir una secuencia aprendida sin input sensorial.
    """
    print("=== Experimento: Memory Replay ===\n")
    
    # Crear TM y aprender secuencia
    tm = TemporalMemory(num_columns=50, cells_per_column=32)
    
    # Secuencia de lugares: A â†’ B â†’ C â†’ D
    patterns = {
        'A': set(range(0, 10)),
        'B': set(range(10, 20)),
        'C': set(range(20, 30)),
        'D': set(range(30, 40)),
    }
    
    sequence = ['A', 'B', 'C', 'D']
    
    # Entrenar bien
    print("Entrenando secuencia...")
    for epoch in range(20):
        tm.reset()
        for _ in range(5):  # Repetir secuencia 5 veces por Ã©poca
            for pattern_name in sequence:
                tm.compute(patterns[pattern_name], learn=True)
    
    print("Entrenamiento completo.\n")
    
    # Test 1: NavegaciÃ³n normal (con input sensorial)
    print("--- Test 1: NavegaciÃ³n Normal (con sensores) ---")
    tm.reset()
    activations_normal = []
    
    for i, pattern_name in enumerate(sequence * 2):  # Repetir 2 veces
        tm.compute(patterns[pattern_name], learn=False)
        activations_normal.append(tm.get_active_columns())
    
    # Test 2: Memory Replay (sin input sensorial despuÃ©s del primer paso)
    print("--- Test 2: Memory Replay (sin sensores) ---")
    tm.reset()
    activations_replay = []
    
    # Solo dar el primer input (A), luego dejar que la red "imagine"
    tm.compute(patterns['A'], learn=False)
    activations_replay.append(tm.get_active_columns())
    
    print("  Paso 1: Input = A (sensorial)")
    
    for i in range(7):  # Intentar 7 pasos mÃ¡s
        # NO DAR INPUT, solo dejar que las predicciones se activen
        # Simular: Las columnas predictivas se convierten en activas
        predicted_cols = tm.get_predictive_columns()
        
        if not predicted_cols:
            print(f"  Paso {i+2}: PredicciÃ³n vacÃ­a â†’ Memory replay terminado")
            break
        
        tm.compute(predicted_cols, learn=False)
        activations_replay.append(tm.get_active_columns())
        
        # Identificar quÃ© patrÃ³n se reprodujo
        for pname, pcols in patterns.items():
            if predicted_cols == pcols:
                print(f"  Paso {i+2}: Reproduciendo {pname} (sin input sensorial!)")
                break
    
    # Visualizar
    fig, axes = plt.subplots(2, 1, figsize=(14, 8))
    
    # Plot 1: NavegaciÃ³n normal
    normal_matrix = np.zeros((len(activations_normal), tm.num_columns))
    for t, active_cols in enumerate(activations_normal):
        for col in active_cols:
            normal_matrix[t, col] = 1
    
    axes[0].imshow(normal_matrix.T, cmap='hot', aspect='auto')
    axes[0].set_title('NavegaciÃ³n Normal (con input sensorial)', fontsize=13, weight='bold')
    axes[0].set_xlabel('Paso de tiempo')
    axes[0].set_ylabel('Columna')
    axes[0].set_yticks([5, 15, 25, 35])
    axes[0].set_yticklabels(['A', 'B', 'C', 'D'])
    
    # Plot 2: Memory replay
    replay_matrix = np.zeros((len(activations_replay), tm.num_columns))
    for t, active_cols in enumerate(activations_replay):
        for col in active_cols:
            replay_matrix[t, col] = 1
    
    axes[1].imshow(replay_matrix.T, cmap='hot', aspect='auto')
    axes[1].set_title('Memory Replay (sin input sensorial despuÃ©s de t=0)', fontsize=13, weight='bold')
    axes[1].set_xlabel('Paso de tiempo')
    axes[1].set_ylabel('Columna')
    axes[1].set_yticks([5, 15, 25, 35])
    axes[1].set_yticklabels(['A', 'B', 'C', 'D'])
    axes[1].axvline(0.5, color='cyan', linestyle='--', linewidth=2, label='Input sensorial')
    axes[1].legend()
    
    plt.tight_layout()
    plt.show()
    
    print("\nÂ¡Observa cÃ³mo la red reproduce la secuencia Aâ†’Bâ†’Câ†’D sin input externo!")
    print("Esto es similar a lo que hacen las ratas durante el sueÃ±o (memory replay)")
    
    return tm

experimento_memory_replay()
```

### Resumen del Notebook 3

```markdown
## âœ… Logros del Notebook 3

1. **Sparse Distributed Representations:**
   - SDR con ~2% de activaciÃ³n
   - Overlap para medir similaridad

2. **Temporal Memory (HTM):**
   - Aprendizaje de secuencias temporales
   - PredicciÃ³n del siguiente estado
   - Estado predictivo vs. activo

3. **Place Cells y Grid Cells:**
   - CÃ©lulas de lugar (activaciÃ³n localizada)
   - CÃ©lulas de grilla (patrÃ³n hexagonal)
   - Sistema de navegaciÃ³n espacial

4. **Memory Replay:**
   - Reproducir secuencias sin input sensorial
   - SimulaciÃ³n de "sueÃ±o" o "imaginaciÃ³n"

5. **Aplicaciones:**
   - PredicciÃ³n de secuencias
   - NavegaciÃ³n espacial
   - PlanificaciÃ³n (reproducir rutas)

## ğŸš€ PrÃ³ximos Pasos (Notebook 4)

- **UI interactiva** con ipycanvas
- **Dibujar neuronas** como pÃ­xeles
- **Robot simulado** navegando en grid
- **Experimentos** de aprendizaje motor
```

---

## ğŸ“˜ Notebook 4: UI Interactiva y RobÃ³tica

### Objetivos

1. **Canvas interactivo** con `ipycanvas` para dibujar neuronas
2. **Controles UI** con `ipywidgets` (play/pause, sliders)
3. **Robot simulado** navegando con CNA
4. **Experimentos** de aprendizaje sensorimotor
5. **IntegraciÃ³n completa** de todos los componentes

### ImplementaciÃ³n

```python
# Celda 1: UI Interactiva Completa
from ipycanvas import Canvas, hold_canvas
import ipywidgets as widgets
from IPython.display import display
import asyncio

class InteractiveCNA:
    """
    Interfaz interactiva para el Connectionist Neural Automaton.
    Permite dibujar, ejecutar, y visualizar en tiempo real.
    """
    
    def __init__(self, grid_size=(64, 64), cell_size=10):
        self.grid_width, self.grid_height = grid_size
        self.cell_size = cell_size
        
        # Canvas dimensions
        self.canvas_width = self.grid_width * cell_size
        self.canvas_height = self.grid_height * cell_size
        
        # Crear CNA
        self.cna = CNA_ConSOM(self.grid_width, self.grid_height)
        
        # Estado de animaciÃ³n
        self.running = False
        self.speed = 10  # Steps per second
        self.current_step = 0
        
        # Estado de dibujo
        self.drawing = False
        self.brush_size = 2
        self.brush_value = 1.0
        self.current_region = config.REGIONES['INTERNA']
        
        # Crear UI
        self._create_canvas()
        self._create_controls()
        self._setup_layout()
        
        # Render inicial
        self._render()
    
    def _create_canvas(self):
        """Crea el canvas principal"""
        self.canvas = Canvas(width=self.canvas_width, height=self.canvas_height)
        
        # Event handlers
        self.canvas.on_mouse_down(self._on_mouse_down)
        self.canvas.on_mouse_move(self._on_mouse_move)
        self.canvas.on_mouse_up(self._on_mouse_up)
    
    def _create_controls(self):
        """Crea controles de la UI"""
        # Botones
        self.btn_play = widgets.Button(description='â–¶ Play', button_style='success')
        self.btn_step = widgets.Button(description='â­ Step', button_style='info')
        self.btn_reset = widgets.Button(description='ğŸ”„ Reset', button_style='warning')
        self.btn_clear = widgets.Button(description='ğŸ—‘ Clear', button_style='danger')
        
        self.btn_play.on_click(self._toggle_play)
        self.btn_step.on_click(self._step_once)
        self.btn_reset.on_click(self._reset)
        self.btn_clear.on_click(self._clear)
        
        # Sliders
        self.slider_speed = widgets.IntSlider(
            value=10, min=1, max=60, step=1,
            description='Speed (fps):', style={'description_width': 'initial'}
        )
        self.slider_speed.observe(self._on_speed_change, 'value')
        
        self.slider_brush = widgets.IntSlider(
            value=2, min=1, max=10, step=1,
            description='Brush Size:', style={'description_width': 'initial'}
        )
        self.slider_brush.observe(self._on_brush_change, 'value')
        
        self.slider_learning_rate = widgets.FloatSlider(
            value=config.COEF_SINAPSIS_ENTRENAMIENTO, min=0.0, max=0.5, step=0.01,
            description='Learning Rate:', style={'description_width': 'initial'}
        )
        
        # Dropdown regiÃ³n
        self.dropdown_region = widgets.Dropdown(
            options=[('ENTRADA', 0), ('SALIDA', 1), ('INTERNA', 2), ('DOLOR', 3)],
            value=2,
            description='Draw Region:',
            style={'description_width': 'initial'}
        )
        self.dropdown_region.observe(self._on_region_change, 'value')
        
        # Checkbox
        self.checkbox_learning = widgets.Checkbox(
            value=True, description='Enable Learning'
        )
        self.checkbox_learning.observe(self._on_learning_toggle, 'value')
        
        # Label para info
        self.label_info = widgets.Label(value=f'Step: 0 | Active neurons: 0')
    
    def _setup_layout(self):
        """Organiza el layout de la UI"""
        # Fila de botones
        buttons = widgets.HBox([self.btn_play, self.btn_step, self.btn_reset, self.btn_clear])
        
        # Controles
        controls = widgets.VBox([
            self.slider_speed,
            self.slider_brush,
            self.slider_learning_rate,
            self.dropdown_region,
            self.checkbox_learning,
            self.label_info
        ])
        
        # Layout principal
        self.layout = widgets.VBox([
            widgets.HTML("<h2>ğŸ§  Connectionist Neural Automaton - Interactive UI</h2>"),
            buttons,
            self.canvas,
            controls
        ])
    
    def display(self):
        """Muestra la UI"""
        display(self.layout)
    
    def _render(self):
        """Renderiza el estado actual del CNA"""
        with hold_canvas(self.canvas):
            self.canvas.clear()
            
            # Dibujar grid
            for y in range(self.grid_height):
                for x in range(self.grid_width):
                    neuron = self.cna.grid[y][x]
                    
                    # Color segÃºn activaciÃ³n y regiÃ³n
                    if neuron.region == config.REGIONES['ENTRADA']:
                        base_color = (100, 149, 237)  # Azul (entrada)
                    elif neuron.region == config.REGIONES['SALIDA']:
                        base_color = (220, 20, 60)    # Rojo (salida)
                    elif neuron.region == config.REGIONES['DOLOR']:
                        base_color = (255, 140, 0)    # Naranja (dolor)
                    else:
                        base_color = (200, 200, 200)  # Gris (interna)
                    
                    # Modular por activaciÃ³n
                    intensity = neuron.valor
                    r = int(base_color[0] * (0.2 + 0.8 * intensity))
                    g = int(base_color[1] * (0.2 + 0.8 * intensity))
                    b = int(base_color[2] * (0.2 + 0.8 * intensity))
                    
                    # Dibujar cÃ©lula
                    self.canvas.fill_style = f'rgb({r},{g},{b})'
                    px = x * self.cell_size
                    py = y * self.cell_size
                    self.canvas.fill_rect(px, py, self.cell_size-1, self.cell_size-1)
            
            # Actualizar info
            active_count = sum(1 for n in self.cna.neuronas if n.valor > 0.5)
            self.label_info.value = f'Step: {self.current_step} | Active neurons: {active_count}/{len(self.cna.neuronas)}'
    
    def _on_mouse_down(self, x, y):
        """Handler para mouse down"""
        self.drawing = True
        self._paint_at(x, y)
    
    def _on_mouse_move(self, x, y):
        """Handler para mouse move"""
        if self.drawing:
            self._paint_at(x, y)
    
    def _on_mouse_up(self, x, y):
        """Handler para mouse up"""
        self.drawing = False
    
    def _paint_at(self, canvas_x, canvas_y):
        """Pinta neuronas en la posiciÃ³n del mouse"""
        # Convertir coordenadas de canvas a grid
        grid_x = int(canvas_x / self.cell_size)
        grid_y = int(canvas_y / self.cell_size)
        
        # Pintar con brush size
        for dy in range(-self.brush_size, self.brush_size + 1):
            for dx in range(-self.brush_size, self.brush_size + 1):
                nx, ny = grid_x + dx, grid_y + dy
                
                # Verificar lÃ­mites
                if 0 <= nx < self.grid_width and 0 <= ny < self.grid_height:
                    neuron = self.cna.grid[ny][nx]
                    neuron.valor = self.brush_value
                    neuron.region = self.current_region
        
        self._render()
    
    def _toggle_play(self, btn):
        """Toggle play/pause"""
        self.running = not self.running
        
        if self.running:
            self.btn_play.description = 'â¸ Pause'
            self.btn_play.button_style = 'warning'
            asyncio.ensure_future(self._animation_loop())
        else:
            self.btn_play.description = 'â–¶ Play'
            self.btn_play.button_style = 'success'
    
    async def _animation_loop(self):
        """Loop de animaciÃ³n"""
        while self.running:
            # Step
            config.COEF_SINAPSIS_ENTRENAMIENTO = self.slider_learning_rate.value
            self.cna.learning_enabled = self.checkbox_learning.value
            
            self.cna.step_with_lateral()
            self.current_step += 1
            
            # Render
            self._render()
            
            # Delay segÃºn speed
            await asyncio.sleep(1.0 / self.speed)
    
    def _step_once(self, btn):
        """Ejecuta un paso"""
        config.COEF_SINAPSIS_ENTRENAMIENTO = self.slider_learning_rate.value
        self.cna.learning_enabled = self.checkbox_learning.value
        
        self.cna.step_with_lateral()
        self.current_step += 1
        self._render()
    
    def _reset(self, btn):
        """Resetea el CNA"""
        self.running = False
        self.btn_play.description = 'â–¶ Play'
        self.btn_play.button_style = 'success'
        
        self.cna.reset()
        self.current_step = 0
        self._render()
    
    def _clear(self, btn):
        """Limpia el canvas (resetea valores pero mantiene pesos)"""
        for neuron in self.cna.neuronas:
            neuron.valor = 0.0
            neuron.activa = False
        
        self._render()
    
    def _on_speed_change(self, change):
        """Handler para cambio de velocidad"""
        self.speed = change['new']
    
    def _on_brush_change(self, change):
        """Handler para cambio de brush size"""
        self.brush_size = change['new']
    
    def _on_region_change(self, change):
        """Handler para cambio de regiÃ³n"""
        self.current_region = change['new']
    
    def _on_learning_toggle(self, change):
        """Handler para toggle de aprendizaje"""
        self.cna.learning_enabled = change['new']

# Crear y mostrar UI
print("Creando UI interactiva...")
ui = InteractiveCNA(grid_size=(48, 48), cell_size=12)
ui.display()

print("\nâœ… UI lista!")
print("ğŸ“ Instrucciones:")
print("  â€¢ Click y arrastra para dibujar neuronas activas")
print("  â€¢ Usa Play para ver la evoluciÃ³n automÃ¡tica")
print("  â€¢ Step para avanzar un paso a la vez")
print("  â€¢ Ajusta sliders para controlar comportamiento")
```

```python
# Celda 2: Robot Simulado
class SimpleRobot:
    """
    Robot simple que navega en un grid 2D.
    """
    
    def __init__(self, grid_size=(20, 20)):
        self.width, self.height = grid_size
        self.position = (grid_size[0] // 2, grid_size[1] // 2)
        self.orientation = 0  # 0=N, 1=E, 2=S, 3=W
        
        # Mundo
        self.world = np.zeros(grid_size)
        self.goal_position = None
        self.obstacles = set()
        
        # Sensores (8 direcciones)
        self.sensor_readings = np.zeros(8)
        
        # Historial
        self.trajectory = [self.position]
    
    def set_goal(self, position: Tuple[int, int]):
        """Establece la posiciÃ³n objetivo"""
        self.goal_position = position
        self.world[position] = 2.0  # Valor alto para objetivo
    
    def add_obstacle(self, position: Tuple[int, int]):
        """AÃ±ade un obstÃ¡culo"""
        self.obstacles.add(position)
        self.world[position] = -1.0  # Valor negativo para obstÃ¡culos
    
    def sense(self) -> np.ndarray:
        """
        Lee sensores (distancia a objetivo y obstÃ¡culos en 8 direcciones).
        """
        directions = [
            (-1, 0),   # N
            (-1, 1),   # NE
            (0, 1),    # E
            (1, 1),    # SE
            (1, 0),    # S
            (1, -1),   # SW
            (0, -1),   # W
            (-1, -1),  # NW
        ]
        
        x, y = self.position
        
        for i, (dx, dy) in enumerate(directions):
            # Raycast en esta direcciÃ³n
            distance_to_goal = float('inf')
            distance_to_obstacle = float('inf')
            
            for step in range(1, max(self.width, self.height)):
                nx, ny = x + dx * step, y + dy * step
                
                # Fuera de lÃ­mites
                if not (0 <= nx < self.height and 0 <= ny < self.width):
                    break
                
                # Objetivo
                if (nx, ny) == self.goal_position:
                    distance_to_goal = step
                    break
                
                # ObstÃ¡culo
                if (nx, ny) in self.obstacles:
                    distance_to_obstacle = step
                    break
            
            # Sensor reading: positivo si objetivo cerca, negativo si obstÃ¡culo cerca
            if distance_to_goal < distance_to_obstacle:
                self.sensor_readings[i] = 1.0 / distance_to_goal if distance_to_goal < 10 else 0.0
            else:
                self.sensor_readings[i] = -1.0 / distance_to_obstacle if distance_to_obstacle < 5 else 0.0
        
        return self.sensor_readings
    
    def move(self, action: str):
        """
        Ejecuta una acciÃ³n: 'forward', 'turn_left', 'turn_right'
        """
        x, y = self.position
        
        if action == 'forward':
            # Mover segÃºn orientaciÃ³n
            direction_map = {0: (-1, 0), 1: (0, 1), 2: (1, 0), 3: (0, -1)}
            dx, dy = direction_map[self.orientation]
            nx, ny = x + dx, y + dy
            
            # Verificar lÃ­mites y obstÃ¡culos
            if (0 <= nx < self.height and 0 <= ny < self.width and 
                (nx, ny) not in self.obstacles):
                self.position = (nx, ny)
                self.trajectory.append(self.position)
        
        elif action == 'turn_left':
            self.orientation = (self.orientation - 1) % 4
        
        elif action == 'turn_right':
            self.orientation = (self.orientation + 1) % 4
    
    def at_goal(self) -> bool:
        """Verifica si llegÃ³ al objetivo"""
        return self.position == self.goal_position
    
    def get_state_vector(self) -> np.ndarray:
        """Estado completo: posiciÃ³n + sensores"""
        # Normalizar posiciÃ³n
        pos_x = self.position[1] / self.width
        pos_y = self.position[0] / self.height
        
        # Normalizar sensores a [0, 1]
        sensors_norm = (self.sensor_readings + 1) / 2
        
        return np.concatenate([[pos_x, pos_y], sensors_norm])
    
    def visualize(self, ax=None):
        """Visualiza el mundo y el robot"""
        if ax is None:
            fig, ax = plt.subplots(figsize=(8, 8))
        
        # Dibujar mundo
        world_vis = self.world.copy()
        world_vis[self.position] = 1.0  # Robot
        
        ax.imshow(world_vis, cmap='RdYlGn', vmin=-1, vmax=2)
        
        # Trayectoria
        if len(self.trajectory) > 1:
            traj = np.array(self.trajectory)
            ax.plot(traj[:, 1], traj[:, 0], 'b-', linewidth=2, alpha=0.6)
        
        # Robot
        rx, ry = self.position
        ax.plot(ry, rx, 'bo', markersize=15)
        
        # OrientaciÃ³n (flecha)
        direction_map = {0: (0, -0.5), 1: (0.5, 0), 2: (0, 0.5), 3: (-0.5, 0)}
        dx, dy = direction_map[self.orientation]
        ax.arrow(ry, rx, dy, dx, head_width=0.3, head_length=0.3, fc='blue', ec='blue')
        
        ax.set_xlim([-0.5, self.width - 0.5])
        ax.set_ylim([self.height - 0.5, -0.5])
        ax.set_aspect('equal')
        ax.grid(True, alpha=0.3)
        
        return ax


class RobotBrainInterface:
    """
    Conecta un CNA con un robot simulado.
    El CNA aprende a navegar el robot hacia el objetivo.
    """
    
    def __init__(self, robot: SimpleRobot, cna_size=(32, 32)):
        self.robot = robot
        self.cna = CNA_ConSOM(*cna_size)
        self.cna_size = cna_size
        
        # Mapear regiones
        # ENTRADA: Sensores del robot
        # SALIDA: Comandos motores (forward, turn_left, turn_right)
    
    def sensors_to_input(self, sensors: np.ndarray):
        """Convierte lecturas de sensores a patrÃ³n de activaciÃ³n"""
        # Normalizar sensores a [0, 1]
        sensors_norm = (sensors + 1) / 2
        
        # Activar regiÃ³n ENTRADA segÃºn sensores
        input_pattern = np.zeros(self.cna_size[0])
        
        # Mapear 8 sensores a ancho de regiÃ³n ENTRADA
        for i, sensor_val in enumerate(sensors_norm):
            # Activar neurona correspondiente
            neuron_idx = int((i / 8) * self.cna_size[0])
            input_pattern[neuron_idx] = sensor_val
        
        return input_pattern
    
    def output_to_action(self) -> str:
        """Lee regiÃ³n SALIDA y decide acciÃ³n"""
        output = self.cna.get_output_region()
        
        # Dividir output en 3 zonas: forward, turn_left, turn_right
        third = len(output) // 3
        
        forward_activation = output[:third].mean()
        left_activation = output[third:2*third].mean()
        right_activation = output[2*third:].mean()
        
        # AcciÃ³n con mayor activaciÃ³n
        activations = {
            'forward': forward_activation,
            'turn_left': left_activation,
            'turn_right': right_activation
        }
        
        return max(activations, key=activations.get)
    
    def step(self) -> Tuple[str, float]:
        """
        Un paso de control:
        1. Leer sensores
        2. Activar CNA
        3. Leer salida
        4. Ejecutar acciÃ³n
        5. Calcular recompensa
        """
        # 1. Sensores
        sensors = self.robot.sense()
        
        # 2. Activar regiÃ³n ENTRADA
        input_pattern = self.sensors_to_input(sensors)
        self.cna.set_input_region(input_pattern)
        
        # 3. Propagar activaciÃ³n (10 pasos internos)
        for _ in range(10):
            self.cna.step_with_lateral()
        
        # 4. Leer salida y ejecutar
        action = self.output_to_action()
        prev_position = self.robot.position
        self.robot.move(action)
        
        # 5. Calcular recompensa
        # Recompensa: Acercarse al objetivo
        if self.robot.at_goal():
            reward = 10.0
        else:
            # Distancia antes y despuÃ©s
            goal = self.robot.goal_position
            dist_before = abs(prev_position[0] - goal[0]) + abs(prev_position[1] - goal[1])
            dist_after = abs(self.robot.position[0] - goal[0]) + abs(self.robot.position[1] - goal[1])
            
            reward = dist_before - dist_after  # Positivo si se acercÃ³
        
        return action, reward
    
    def train_episode(self, max_steps=100, visualize=False):
        """Entrena un episodio completo"""
        self.robot.trajectory = [self.robot.position]
        total_reward = 0
        actions_taken = []
        
        for step in range(max_steps):
            action, reward = self.step()
            total_reward += reward
            actions_taken.append(action)
            
            # Reforzar o debilitar pesos segÃºn recompensa
            if reward > 0:
                # Reforzar conexiones activas
                config.COEF_SINAPSIS_ENTRENAMIENTO = 0.1
            else:
                # Debilitar
                config.COEF_SINAPSIS_ENTRENAMIENTO = -0.05
            
            # Si llegÃ³ al objetivo, terminar
            if self.robot.at_goal():
                print(f"Â¡Objetivo alcanzado en {step+1} pasos!")
                break
        
        if visualize:
            fig, ax = plt.subplots(figsize=(8, 8))
            self.robot.visualize(ax)
            ax.set_title(f'Episodio - Recompensa total: {total_reward:.2f}', fontsize=12)
            plt.show()
        
        return total_reward, len(actions_taken)
```

```python
# Celda 3: Experimento - Robot aprendiendo navegaciÃ³n
def experimento_robot_navegacion():
    """
    Entrena un robot a navegar hacia un objetivo usando CNA.
    """
    print("=== Experimento: Robot con Cerebro CNA ===\n")
    
    # Crear mundo
    robot = SimpleRobot(grid_size=(20, 20))
    robot.set_goal((18, 18))  # Esquina inferior derecha
    
    # AÃ±adir obstÃ¡culos
    for i in range(5, 15):
        robot.add_obstacle((i, 10))  # Pared vertical
    
    # Crear interfaz
    interface = RobotBrainInterface(robot, cna_size=(32, 32))
    
    # Entrenar varios episodios
    num_episodes = 20
    rewards = []
    steps_taken = []
    
    for episode in range(num_episodes):
        # Resetear robot
        robot.position = (1, 1)  # Esquina superior izquierda
        robot.orientation = 0
        robot.trajectory = [robot.position]
        
        # Ejecutar episodio
        total_reward, steps = interface.train_episode(
            max_steps=150, 
            visualize=(episode % 5 == 0)  # Visualizar cada 5 episodios
        )
        
        rewards.append(total_reward)
        steps_taken.append(steps)
        
        print(f"Episodio {episode+1}: Recompensa={total_reward:.2f}, Pasos={steps}")
    
    # Plot aprendizaje
    fig, axes = plt.subplots(1, 2, figsize=(15, 5))
    
    axes[0].plot(range(1, num_episodes+1), rewards, marker='o', linewidth=2)
    axes[0].set_xlabel('Episodio')
    axes[0].set_ylabel('Recompensa Total')
    axes[0].set_title('Progreso de Aprendizaje', fontsize=13, weight='bold')
    axes[0].grid(True, alpha=0.3)
    
    axes[1].plot(range(1, num_episodes+1), steps_taken, marker='s', linewidth=2, color='orange')
    axes[1].set_xlabel('Episodio')
    axes[1].set_ylabel('Pasos hasta objetivo')
    axes[1].set_title('Eficiencia de NavegaciÃ³n', fontsize=13, weight='bold')
    axes[1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    print("\nâœ… Observa cÃ³mo:")
    print("  1. Primeros episodios: El robot explora aleatoriamente")
    print("  2. Episodios medios: Empieza a encontrar rutas")
    print("  3. Ãšltimos episodios: NavegaciÃ³n mÃ¡s eficiente")
    print("  4. Los pesos sinÃ¡pticos aprenden la polÃ­tica de navegaciÃ³n")
    
    return interface

experimento_robot_navegacion()
```

### Guardar y Compartir

```python
# Celda 4: Exportar animaciÃ³n
from matplotlib.animation import FuncAnimation, PillowWriter

def crear_animacion_cna(cna: ConnessionistNeuralAutomaton, num_steps=100, interval=50):
    """
    Crea una animaciÃ³n GIF de la evoluciÃ³n del CNA.
    """
    fig, ax = plt.subplots(figsize=(8, 8))
    
    states = []
    for _ in range(num_steps):
        states.append(cna.get_state().copy())
        cna.step_with_lateral()
    
    im = ax.imshow(states[0], cmap='hot', vmin=0, vmax=1, animated=True)
    ax.axis('off')
    
    def update(frame):
        im.set_array(states[frame])
        ax.set_title(f'CNA Evolution - Step {frame}', fontsize=14, weight='bold')
        return [im]
    
    anim = FuncAnimation(fig, update, frames=num_steps, interval=interval, blit=True)
    
    # Guardar como GIF
    writer = PillowWriter(fps=20)
    anim.save('cna_evolution.gif', writer=writer)
    print("âœ… AnimaciÃ³n guardada como 'cna_evolution.gif'")
    
    plt.close()
    return anim

# Ejemplo (descomentar para usar)
# cna_demo = CNA_ConSOM(48, 48)
# # Activar algunos puntos
# for _ in range(20):
#     x, y = random.randint(0, 47), random.randint(0, 15)
#     cna_demo.grid[y][x].valor = 1.0
# 
# crear_animacion_cna(cna_demo, num_steps=100)
```

### Resumen del Notebook 4

```markdown
## âœ… Logros del Notebook 4

1. **UI Interactiva Completa:**
   - Canvas para dibujar neuronas con mouse
   - Controles (play/pause, step, reset, clear)
   - Sliders para velocidad, brush, learning rate
   - VisualizaciÃ³n en tiempo real

2. **Robot Simulado:**
   - NavegaciÃ³n en grid 2D
   - 8 sensores direccionales
   - 3 acciones (forward, turn_left, turn_right)
   - DetecciÃ³n de objetivos y obstÃ¡culos

3. **IntegraciÃ³n CNA-Robot:**
   - Sensores â†’ RegiÃ³n ENTRADA
   - RegiÃ³n SALIDA â†’ Acciones motoras
   - Aprendizaje por refuerzo (Hebbian + reward)

4. **Experimentos:**
   - Robot aprendiendo navegaciÃ³n
   - Evitar obstÃ¡culos
   - Encontrar objetivo

5. **ExportaciÃ³n:**
   - Guardar estados como pickle
   - Crear animaciones GIF

## ğŸ‰ Â¡Proyecto Completo!

Has implementado un **Connectionist Neural Automaton** completo con:

âœ… AutÃ³mata celular neuronal base  
âœ… Self-organizing maps (Kohonen)  
âœ… Memoria temporal (HTM)  
âœ… UI interactiva (ipycanvas)  
âœ… RobÃ³tica (navegaciÃ³n sensorimotor)

### PrÃ³ximos Pasos Avanzados:

1. **Conectar con transformers** (embeddings de lenguaje)
2. **JerarquÃ­a de niveles** (HTM multi-capa)
3. **Entornos 3D** (PyBullet, MuJoCo)
4. **Clustering dinÃ¡mico** (nuevas regiones emergentes)
5. **IntegraciÃ³n con LLMs** (instrucciones en lenguaje natural â†’ acciones)
```

---

## ğŸŒ Compartir en la Web

### OpciÃ³n 1: Google Colab (Recomendado)

**Ventajas:**
- GPU gratuita (T4, P100)
- No requiere instalaciÃ³n
- FÃ¡cil de compartir

**Pasos:**

1. **Subir notebooks a tu repositorio:**
   ```bash
   cd /ruta/a/tu/proyecto
   git add notebooks/*.ipynb
   git commit -m "Add CNA notebooks"
   git push origin master
   ```

2. **Crear enlaces de Colab:**
   - Reemplaza `https://github.com/` con `https://colab.research.google.com/github/`
   - Ejemplo:
     ```
     GitHub: https://github.com/tuusuario/CNA_Project/blob/master/notebooks/01_Automata_Base.ipynb
     Colab:  https://colab.research.google.com/github/tuusuario/CNA_Project/blob/master/notebooks/01_Automata_Base.ipynb
     ```

3. **AÃ±adir badges al README:**
   ```markdown
   [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tuusuario/CNA_Project/blob/master/notebooks/01_Automata_Base.ipynb)
   ```

**Configurar GPU en Colab:**
```python
# Primera celda del notebook
!nvidia-smi  # Verificar GPU disponible

# Runtime > Change runtime type > Hardware accelerator > GPU
```

### OpciÃ³n 2: Binder

**Ventajas:**
- 100% open-source
- Sin necesidad de cuenta
- Reproducibilidad perfecta

**Pasos:**

1. **AÃ±adir `environment.yml` o `requirements.txt`** (ya incluido en el proyecto)

2. **Ir a mybinder.org** y crear enlace:
   - Repository: `https://github.com/tuusuario/CNA_Project`
   - Branch: `master`
   - Path to a notebook: `notebooks/01_Automata_Base.ipynb`

3. **Badge:**
   ```markdown
   [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/tuusuario/CNA_Project/HEAD?labpath=notebooks%2F01_Automata_Base.ipynb)
   ```

### OpciÃ³n 3: GitHub Pages (Solo visualizaciÃ³n)

**Para mostrar notebooks renderizados:**

1. **Usar nbviewer:**
   ```markdown
   [![View on nbviewer](https://img.shields.io/badge/render-nbviewer-orange.svg)](https://nbviewer.org/github/tuusuario/CNA_Project/blob/master/notebooks/01_Automata_Base.ipynb)
   ```

2. **O convertir a HTML:**
   ```bash
   jupyter nbconvert --to html notebooks/01_Automata_Base.ipynb
   ```

---

## ğŸ“š ApÃ©ndices

### A. Conceptos Clave

**1. Conexionismo**
- Paradigma que modela cogniciÃ³n como redes de unidades simples interconectadas
- Sin procesador central (vs. cognitivismo clÃ¡sico)
- Aprendizaje distribuido

**2. AutÃ³mata Celular**
- Sistema discreto de cÃ©lulas en grid
- Cada cÃ©lula tiene estado finito
- Reglas locales â†’ comportamiento global emergente

**3. Hebbian Learning**
- "Neurons that fire together, wire together"
- Regla: Î”w = Î· Â· pre Â· post
- Fundamento del aprendizaje asociativo

**4. Sparse Distributed Representation (SDR)**
- Solo ~2% de neuronas activas
- Alta capacidad de representaciÃ³n
- Robusto a ruido

**5. Predictive Coding**
- Cerebro como mÃ¡quina de predicciÃ³n
- Minimiza error de predicciÃ³n
- Fundamental en HTM

### B. ConfiguraciÃ³n de Colab

```python
# Celda de configuraciÃ³n para Colab
import sys

# Verificar si estamos en Colab
IN_COLAB = 'google.colab' in sys.modules

if IN_COLAB:
    print("ğŸ”§ Configurando Google Colab...")
    
    # Verificar GPU
    !nvidia-smi
    
    # Instalar dependencias (si no estÃ¡n en requirements.txt)
    !pip install -q torch torchvision ipycanvas ipywidgets
    
    # Habilitar widgets
    from google.colab import output
    output.enable_custom_widget_manager()
    
    print("âœ… ConfiguraciÃ³n completa!")
else:
    print("ğŸ’» Ejecutando localmente")
```

### C. Troubleshooting

**Problema: ipycanvas no funciona en Jupyter Lab**
```bash
# SoluciÃ³n: Instalar extensiÃ³n
jupyter labextension install @jupyter-widgets/jupyterlab-manager ipycanvas
```

**Problema: GPU no detectada en Colab**
```python
# Verificar disponibilidad
import torch
print(f"CUDA available: {torch.cuda.is_available()}")
print(f"CUDA device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'N/A'}")

# Si no estÃ¡ disponible: Runtime > Change runtime type > GPU
```

**Problema: Memoria insuficiente**
```python
# Reducir tamaÃ±o del grid
cna = CNA_ConSOM(32, 32)  # En vez de 64x64

# O reducir batch size en entrenamiento
```

### D. Optimizaciones Avanzadas

**1. Usar torch.compile() (PyTorch 2.0+)**
```python
import torch

@torch.compile(mode="reduce-overhead")
def cna_step_optimized(states, weights):
    return torch.nn.functional.conv2d(states, weights)

# 100x mÃ¡s rÃ¡pido que loops Python
```

**2. Mixed Precision**
```python
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()

with autocast():
    output = model(input)
    loss = criterion(output, target)

scaler.scale(loss).backward()
scaler.step(optimizer)
scaler.update()
```

**3. Paralelizar con multiprocessing**
```python
from multiprocessing import Pool

def train_episode(episode_id):
    # Entrenar un episodio
    return reward

# Entrenar 10 episodios en paralelo
with Pool(10) as p:
    rewards = p.map(train_episode, range(10))
```

### E. Referencias y Lecturas

**Papers Fundamentales:**

1. **Temporal Memory:**
   - Hawkins, J., & Ahmad, S. (2016). "Why Neurons Have Thousands of Synapses, a Theory of Sequence Memory in Neocortex"

2. **Place & Grid Cells:**
   - O'Keefe, J., & Dostrovsky, J. (1971). "The hippocampus as a spatial map"
   - Hafting, T. et al. (2005). "Microstructure of a spatial map in the entorhinal cortex"

3. **Self-Organizing Maps:**
   - Kohonen, T. (1990). "The self-organizing map"

4. **Neural Cellular Automata:**
   - Mordvintsev, A. et al. (2020). "Growing Neural Cellular Automata"

5. **Predictive Coding:**
   - Rao, R. P., & Ballard, D. H. (1999). "Predictive coding in the visual cortex"

**Libros:**

1. **On Intelligence** - Jeff Hawkins (2004)
   - TeorÃ­a del neocÃ³rtex como sistema predictivo

2. **A Thousand Brains** - Jeff Hawkins (2021)
   - TeorÃ­a de mÃºltiples mapas corticales

3. **Consciousness Explained** - Daniel Dennett (1991)
   - CrÃ­tica al teatro cartesiano

4. **Parallel Distributed Processing** - Rumelhart & McClelland (1986)
   - Fundamentos del conexionismo

**Recursos Online:**

- Numenta Research: https://numenta.com/research
- Distill.pub: https://distill.pub (visualizaciones interactivas)
- HTM School: https://www.youtube.com/c/NumentaTheory (videos explicativos)

---

## ğŸ“„ README.md del Proyecto

```markdown
# ğŸ§  Connectionist Neural Automaton (CNA)

**Un AutÃ³mata Celular Neuronal para la BÃºsqueda de Inteligencia Artificial**

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tuusuario/CNA_Project/blob/master/notebooks/01_Automata_Base.ipynb)
[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/tuusuario/CNA_Project/HEAD?labpath=notebooks)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## ğŸ¯ VisiÃ³n

Este proyecto implementa un **autÃ³mata celular neuronal** que unifica:

- **Kohonen** (Self-Organizing Maps, inhibiciÃ³n lateral tipo sombrero mexicano)
- **Hawkins** (Hierarchical Temporal Memory, predicciÃ³n temporal)
- **Place/Grid Cells** (mapas espaciales emergentes, navegaciÃ³n)
- **Dennett** (consciencia distribuida, sin teatro cartesiano)
- **Neural Cellular Automata** (reglas aprendidas, no hardcoded)

**Objetivo:** Cerrar la brecha entre IA de lenguaje y robÃ³tica mÃ³vil, creando cerebros de bajo nivel escalables desde organismos simples (Aplysia, mosca) hasta sistemas complejos.

---

## âœ¨ CaracterÃ­sticas

- âœ… **AutÃ³mata Celular Neuronal** con reglas emergentes (Hebbian learning)
- âœ… **Self-Organizing Maps** con inhibiciÃ³n lateral (Mexican Hat)
- âœ… **Memoria Temporal** (HTM) con predicciÃ³n de secuencias
- âœ… **Place & Grid Cells** para navegaciÃ³n espacial
- âœ… **UI Interactiva** (ipycanvas) para dibujar y visualizar
- âœ… **Robot Simulado** con aprendizaje sensorimotor
- âœ… **Notebooks didÃ¡cticos** en espaÃ±ol con explicaciones paso a paso

---

## ğŸš€ Inicio RÃ¡pido

### OpciÃ³n 1: Google Colab (Recomendado)

1. Click en el badge de Colab arriba
2. Runtime > Change runtime type > GPU
3. Ejecutar celdas secuencialmente

### OpciÃ³n 2: Local

```bash
# Clonar repositorio
git clone https://github.com/tuusuario/CNA_Project.git
cd CNA_Project

# Crear entorno
conda env create -f environment.yml
conda activate cna

# O con pip
pip install -r requirements.txt

# Lanzar Jupyter
jupyter lab
```

---

## ğŸ“š Notebooks

1. **[01_Automata_Base.ipynb](notebooks/01_Automata_Base.ipynb)**
   - Clases base: Neurona, Dendrita, Sinapsis
   - AutÃ³mata celular con regiones (ENTRADA/SALIDA/INTERNA)
   - Experimentos: PropagaciÃ³n de onda, reflejos simples

2. **[02_SOM_Kohonen.ipynb](notebooks/02_SOM_Kohonen.ipynb)**
   - Self-Organizing Maps
   - FunciÃ³n Mexican Hat (inhibiciÃ³n lateral)
   - Clustering de colores, mapas tonotÃ³picos

3. **[03_HTM_Prediccion.ipynb](notebooks/03_HTM_Prediccion.ipynb)**
   - Sparse Distributed Representations (SDR)
   - Temporal Memory (secuencias)
   - Place & Grid Cells (navegaciÃ³n espacial)
   - Memory Replay

4. **[04_UI_Robotica.ipynb](notebooks/04_UI_Robotica.ipynb)**
   - UI interactiva con ipycanvas
   - Robot simulado navegando con CNA
   - Aprendizaje sensorimotor

---

## ğŸ§ª Ejemplos de Uso

### Crear un CNA

```python
from src.cna import ConnessionistNeuralAutomaton

# Crear autÃ³mata 64x64
cna = ConnessionistNeuralAutomaton(64, 64, connect_radius=3)

# Activar regiÃ³n de entrada
import numpy as np
cna.set_input_region(np.random.rand(64) * 0.5)

# Ejecutar 100 pasos
for _ in range(100):
    cna.step()

# Visualizar
cna.visualize()
```

### Robot con CNA

```python
from src.robot import SimpleRobot, RobotBrainInterface

# Crear robot
robot = SimpleRobot(grid_size=(20, 20))
robot.set_goal((18, 18))

# Conectar con CNA
interface = RobotBrainInterface(robot, cna_size=(32, 32))

# Entrenar navegaciÃ³n
for episode in range(10):
    interface.train_episode(max_steps=100, visualize=True)
```

---

## ğŸ”¬ Fundamentos CientÃ­ficos

Este proyecto se basa en investigaciones recientes:

- **Zebrafish whole-brain imaging** (2024): Mapeo completo de actividad neuronal
- **Predictive grid cells** (2024): CÃ©lulas que predicen posiciÃ³n futura
- **Neural Cellular Automata** (2020, Google): AutÃ³matas con reglas aprendidas
- **HTM Theory** (Numenta): Memoria temporal jerÃ¡rquica
- **Place & Grid Cells** (Nobel 2014): Mapas espaciales en hipocampo

Ver [PROYECTO_JUPYTER.md](PROYECTO_JUPYTER.md) para detalles completos.

---

## ğŸ¤ Contribuir

Â¡Contribuciones son bienvenidas!

1. Fork el proyecto
2. Crea tu rama (`git checkout -b feature/AmazingFeature`)
3. Commit cambios (`git commit -m 'Add AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

---

## ğŸ“œ Licencia

MIT License - Ver [LICENSE](LICENSE) para detalles

---

## ğŸ™ Agradecimientos

- **Jeff Hawkins** (Numenta) - TeorÃ­a HTM
- **Teuvo Kohonen** - Self-Organizing Maps
- **Daniel Dennett** - Consciencia distribuida
- **Eric Kandel** - Neurociencia de Aplysia
- **Google Research** - Neural Cellular Automata

---

## ğŸ“§ Contacto

Tu Nombre - [@tutwitter](https://twitter.com/tutwitter) - email@ejemplo.com

Proyecto Link: [https://github.com/tuusuario/CNA_Project](https://github.com/tuusuario/CNA_Project)

---

**â­ Si este proyecto te resulta Ãºtil, considera darle una estrella en GitHub!**
```

---

## ğŸ“ ConclusiÃ³n

Has creado un **Connectionist Neural Automaton** completo que:

1. âœ… **Unifica teorÃ­as neurocientÃ­ficas** (Kohonen, Hawkins, Dennett)
2. âœ… **Escala desde sistemas simples** (Aplysia) a complejos (pez cebra)
3. âœ… **Integra percepciÃ³n y acciÃ³n** (robÃ³tica embodied)
4. âœ… **Aprende reglas emergentes** (no hardcoded)
5. âœ… **Es reproducible y educativo** (notebooks en espaÃ±ol)

### PrÃ³ximos DesafÃ­os

1. **Conectar con transformers** para procesamiento simbÃ³lico de alto nivel
2. **JerarquÃ­as profundas** (HTM multi-capa)
3. **Entornos 3D** (simuladores fÃ­sicos)
4. **Hardware dedicado** (neuromorphic computing)
5. **Aplicaciones reales** (drones, robots mÃ³viles, prÃ³tesis)

### El Camino hacia la IA Completa

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ARQUITECTURA COMPLETA                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  [NIVEL SIMBÃ“LICO]                                      â”‚
â”‚   Transformers, LLMs                                     â”‚
â”‚   â€¢ Razonamiento abstracto                              â”‚
â”‚   â€¢ Lenguaje natural                                     â”‚
â”‚            â†• Embeddings â†•                               â”‚
â”‚  [NIVEL INTERMEDIO]                                      â”‚
â”‚   Hierarchical Temporal Memory                           â”‚
â”‚   â€¢ Patrones temporales                                  â”‚
â”‚   â€¢ Memoria episÃ³dica                                    â”‚
â”‚            â†• Secuencias â†•                               â”‚
â”‚  [NIVEL BAJO - CNA]                                      â”‚
â”‚   Connectionist Neural Automaton                         â”‚
â”‚   â€¢ Mapas auto-organizados                              â”‚
â”‚   â€¢ NavegaciÃ³n espacial                                  â”‚
â”‚   â€¢ Control sensorimotor                                 â”‚
â”‚            â†• Sensores â†•                                 â”‚
â”‚  [MUNDO FÃSICO]                                          â”‚
â”‚   Robot, Cuerpo, Entorno                                â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

**Â¡Has dado el primer paso hacia la construcciÃ³n de una IA verdaderamente embodied!** ğŸš€ğŸ§ ğŸ¤–

---

*Documento creado por: [Tu Nombre]*  
*Fecha: Febrero 2026*  
*VersiÃ³n: 1.0*